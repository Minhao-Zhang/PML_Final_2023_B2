{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 23.199743\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: -18.840620\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: -21.619537\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: -23.397123\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: -23.421837\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: -23.962269\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: -23.813662\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: -24.145775\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: -24.125254\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: -24.285126\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: -24.210777\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: -24.026129\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: -24.158344\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: -24.107502\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: -24.564007\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: -24.401659\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: -24.241386\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: -24.662386\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: -24.720373\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: -24.489574\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: -24.819639\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: -24.730621\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: -25.190706\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: -24.981747\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: -24.944189\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: -25.001066\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: -25.028168\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: -25.136173\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: -25.167139\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: -25.397612\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: -25.319363\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: -25.183243\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: -25.233078\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: -25.221922\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: -25.160734\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: -25.353840\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: -25.691994\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: -25.459230\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: -25.998560\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: -25.561777\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: -25.581715\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: -25.705704\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: -25.887371\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: -26.160927\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: -25.999756\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: -26.199818\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: -25.906187\n",
      "====> Epoch: 1 Average loss: -24.3414\n",
      "====> Test set loss: -26.3616\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: -26.147337\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: -26.107056\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: -26.342272\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: -26.008892\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: -25.613796\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: -26.411222\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: -26.104185\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: -26.488775\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: -26.421108\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: -26.500736\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: -26.769304\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: -26.934898\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: -26.680677\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: -26.134298\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: -26.620253\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: -27.231792\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: -26.994539\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: -26.726042\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: -27.042381\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: -26.805771\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: -26.603029\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: -26.686836\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: -26.929621\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: -27.348640\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: -27.030664\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: -27.059540\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: -27.165438\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: -27.074377\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: -26.991499\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: -27.178757\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: -27.152166\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: -27.167976\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: -26.936445\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: -27.407692\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: -27.253939\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: -27.081467\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: -27.598448\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: -27.502586\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: -27.071301\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: -27.326561\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: -27.484926\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: -27.466719\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: -27.341133\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: -27.323750\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: -27.524708\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: -27.583776\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: -27.086906\n",
      "====> Epoch: 2 Average loss: -26.9348\n",
      "====> Test set loss: -27.8327\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: -27.447386\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: -27.542198\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: -27.613684\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: -27.932871\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: -27.839149\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: -27.625050\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: -27.735537\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: -27.676767\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: -27.736258\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: -27.664970\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: -27.646509\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: -27.786713\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: -27.842726\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: -27.551281\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: -27.634434\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: -27.550884\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: -28.199167\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: -27.617643\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: -27.770601\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: -27.883028\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: -28.021490\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: -28.131010\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: -27.707405\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: -27.893009\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: -27.999065\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: -27.770975\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: -28.020586\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: -28.102823\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: -28.289402\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: -28.333773\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: -27.987160\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: -28.085810\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: -28.077848\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: -28.292604\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: -28.077475\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: -28.130634\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: -27.504990\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: -27.830507\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: -27.869698\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: -27.766949\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: -27.985647\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: -27.703611\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: -27.842018\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: -27.832739\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: -27.595018\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: -27.726292\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: -28.090166\n",
      "====> Epoch: 3 Average loss: -27.8942\n",
      "====> Test set loss: -28.1749\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: -28.132412\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tLoss: -27.571165\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tLoss: -28.035234\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tLoss: -27.902416\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tLoss: -27.978281\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: -28.035902\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tLoss: -28.357214\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tLoss: -28.039801\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tLoss: -28.614658\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tLoss: -27.878777\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: -28.245445\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tLoss: -27.981483\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tLoss: -28.491617\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tLoss: -28.174631\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tLoss: -28.511076\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: -28.236296\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tLoss: -28.194679\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tLoss: -27.968603\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tLoss: -28.461119\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tLoss: -28.334887\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: -28.502148\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tLoss: -28.094254\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tLoss: -28.551235\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tLoss: -28.479244\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tLoss: -28.160908\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: -28.306345\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tLoss: -28.103222\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tLoss: -28.480694\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tLoss: -28.455864\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tLoss: -28.081125\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: -28.294720\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tLoss: -28.275633\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tLoss: -28.168516\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tLoss: -28.595039\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tLoss: -28.152485\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: -28.480433\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tLoss: -28.513395\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tLoss: -28.594362\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tLoss: -28.572767\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tLoss: -28.622028\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: -28.456324\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tLoss: -28.300667\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tLoss: -28.343758\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tLoss: -28.873814\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tLoss: -28.428808\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: -28.769957\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tLoss: -28.157299\n",
      "====> Epoch: 4 Average loss: -28.2973\n",
      "====> Test set loss: -28.7462\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: -28.024263\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tLoss: -28.335546\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tLoss: -28.574017\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tLoss: -28.381258\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tLoss: -28.225225\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: -28.505116\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tLoss: -27.922939\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tLoss: -27.958315\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tLoss: -28.340208\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tLoss: -28.247250\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: -28.206064\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tLoss: -28.062328\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tLoss: -28.908136\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tLoss: -28.601202\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tLoss: -28.400270\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: -28.631001\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tLoss: -28.396755\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tLoss: -28.327011\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tLoss: -28.229694\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tLoss: -28.429237\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: -28.492441\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tLoss: -28.613754\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tLoss: -28.474842\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tLoss: -28.726437\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tLoss: -28.503330\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: -28.433384\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tLoss: -28.496820\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tLoss: -28.438194\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tLoss: -28.563976\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tLoss: -28.853943\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: -28.779882\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tLoss: -28.728733\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tLoss: -29.100649\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tLoss: -28.941772\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tLoss: -28.858038\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: -28.394688\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tLoss: -28.889023\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tLoss: -28.603954\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tLoss: -28.706306\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tLoss: -28.372705\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: -28.161728\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tLoss: -28.889820\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tLoss: -28.548517\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tLoss: -28.374882\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tLoss: -28.479050\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: -28.808342\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tLoss: -28.706835\n",
      "====> Epoch: 5 Average loss: -28.5024\n",
      "====> Test set loss: -28.9893\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: -29.046032\n",
      "Train Epoch: 6 [1280/60000 (2%)]\tLoss: -28.211987\n",
      "Train Epoch: 6 [2560/60000 (4%)]\tLoss: -28.552599\n",
      "Train Epoch: 6 [3840/60000 (6%)]\tLoss: -28.401764\n",
      "Train Epoch: 6 [5120/60000 (9%)]\tLoss: -28.543102\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: -28.860376\n",
      "Train Epoch: 6 [7680/60000 (13%)]\tLoss: -28.369896\n",
      "Train Epoch: 6 [8960/60000 (15%)]\tLoss: -28.791676\n",
      "Train Epoch: 6 [10240/60000 (17%)]\tLoss: -28.629089\n",
      "Train Epoch: 6 [11520/60000 (19%)]\tLoss: -28.580904\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: -28.835289\n",
      "Train Epoch: 6 [14080/60000 (23%)]\tLoss: -28.503527\n",
      "Train Epoch: 6 [15360/60000 (26%)]\tLoss: -28.782112\n",
      "Train Epoch: 6 [16640/60000 (28%)]\tLoss: -28.968245\n",
      "Train Epoch: 6 [17920/60000 (30%)]\tLoss: -28.781179\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: -28.863419\n",
      "Train Epoch: 6 [20480/60000 (34%)]\tLoss: -29.074295\n",
      "Train Epoch: 6 [21760/60000 (36%)]\tLoss: -29.110451\n",
      "Train Epoch: 6 [23040/60000 (38%)]\tLoss: -28.755270\n",
      "Train Epoch: 6 [24320/60000 (41%)]\tLoss: -28.712805\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: -28.974152\n",
      "Train Epoch: 6 [26880/60000 (45%)]\tLoss: -28.637367\n",
      "Train Epoch: 6 [28160/60000 (47%)]\tLoss: -28.564510\n",
      "Train Epoch: 6 [29440/60000 (49%)]\tLoss: -28.725424\n",
      "Train Epoch: 6 [30720/60000 (51%)]\tLoss: -28.654867\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: -28.727821\n",
      "Train Epoch: 6 [33280/60000 (55%)]\tLoss: -28.796675\n",
      "Train Epoch: 6 [34560/60000 (58%)]\tLoss: -28.700762\n",
      "Train Epoch: 6 [35840/60000 (60%)]\tLoss: -28.676085\n",
      "Train Epoch: 6 [37120/60000 (62%)]\tLoss: -28.836159\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: -28.709667\n",
      "Train Epoch: 6 [39680/60000 (66%)]\tLoss: -28.818106\n",
      "Train Epoch: 6 [40960/60000 (68%)]\tLoss: -28.573381\n",
      "Train Epoch: 6 [42240/60000 (70%)]\tLoss: -28.655897\n",
      "Train Epoch: 6 [43520/60000 (72%)]\tLoss: -28.505260\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: -28.820351\n",
      "Train Epoch: 6 [46080/60000 (77%)]\tLoss: -28.800562\n",
      "Train Epoch: 6 [47360/60000 (79%)]\tLoss: -28.898163\n",
      "Train Epoch: 6 [48640/60000 (81%)]\tLoss: -28.612595\n",
      "Train Epoch: 6 [49920/60000 (83%)]\tLoss: -28.950294\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: -28.571651\n",
      "Train Epoch: 6 [52480/60000 (87%)]\tLoss: -28.690163\n",
      "Train Epoch: 6 [53760/60000 (90%)]\tLoss: -28.706009\n",
      "Train Epoch: 6 [55040/60000 (92%)]\tLoss: -28.762186\n",
      "Train Epoch: 6 [56320/60000 (94%)]\tLoss: -28.594597\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: -28.491625\n",
      "Train Epoch: 6 [58880/60000 (98%)]\tLoss: -28.825006\n",
      "====> Epoch: 6 Average loss: -28.7469\n",
      "====> Test set loss: -29.0924\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: -28.633377\n",
      "Train Epoch: 7 [1280/60000 (2%)]\tLoss: -28.801470\n",
      "Train Epoch: 7 [2560/60000 (4%)]\tLoss: -28.644939\n",
      "Train Epoch: 7 [3840/60000 (6%)]\tLoss: -28.890177\n",
      "Train Epoch: 7 [5120/60000 (9%)]\tLoss: -28.923487\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: -28.684677\n",
      "Train Epoch: 7 [7680/60000 (13%)]\tLoss: -28.933392\n",
      "Train Epoch: 7 [8960/60000 (15%)]\tLoss: -28.723015\n",
      "Train Epoch: 7 [10240/60000 (17%)]\tLoss: -28.982777\n",
      "Train Epoch: 7 [11520/60000 (19%)]\tLoss: -28.909849\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: -28.837746\n",
      "Train Epoch: 7 [14080/60000 (23%)]\tLoss: -28.568058\n",
      "Train Epoch: 7 [15360/60000 (26%)]\tLoss: -28.704578\n",
      "Train Epoch: 7 [16640/60000 (28%)]\tLoss: -28.749743\n",
      "Train Epoch: 7 [17920/60000 (30%)]\tLoss: -28.942957\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: -29.090721\n",
      "Train Epoch: 7 [20480/60000 (34%)]\tLoss: -28.961658\n",
      "Train Epoch: 7 [21760/60000 (36%)]\tLoss: -28.857422\n",
      "Train Epoch: 7 [23040/60000 (38%)]\tLoss: -28.754929\n",
      "Train Epoch: 7 [24320/60000 (41%)]\tLoss: -28.848206\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: -28.920300\n",
      "Train Epoch: 7 [26880/60000 (45%)]\tLoss: -28.717075\n",
      "Train Epoch: 7 [28160/60000 (47%)]\tLoss: -28.543980\n",
      "Train Epoch: 7 [29440/60000 (49%)]\tLoss: -28.624722\n",
      "Train Epoch: 7 [30720/60000 (51%)]\tLoss: -28.852371\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: -28.536711\n",
      "Train Epoch: 7 [33280/60000 (55%)]\tLoss: -28.540955\n",
      "Train Epoch: 7 [34560/60000 (58%)]\tLoss: -28.678038\n",
      "Train Epoch: 7 [35840/60000 (60%)]\tLoss: -28.633226\n",
      "Train Epoch: 7 [37120/60000 (62%)]\tLoss: -28.768856\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: -29.161482\n",
      "Train Epoch: 7 [39680/60000 (66%)]\tLoss: -29.100266\n",
      "Train Epoch: 7 [40960/60000 (68%)]\tLoss: -29.200323\n",
      "Train Epoch: 7 [42240/60000 (70%)]\tLoss: -29.313828\n",
      "Train Epoch: 7 [43520/60000 (72%)]\tLoss: -28.586805\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: -28.943163\n",
      "Train Epoch: 7 [46080/60000 (77%)]\tLoss: -29.043098\n",
      "Train Epoch: 7 [47360/60000 (79%)]\tLoss: -28.652927\n",
      "Train Epoch: 7 [48640/60000 (81%)]\tLoss: -28.594440\n",
      "Train Epoch: 7 [49920/60000 (83%)]\tLoss: -28.896555\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: -29.073412\n",
      "Train Epoch: 7 [52480/60000 (87%)]\tLoss: -28.679958\n",
      "Train Epoch: 7 [53760/60000 (90%)]\tLoss: -28.332485\n",
      "Train Epoch: 7 [55040/60000 (92%)]\tLoss: -29.192026\n",
      "Train Epoch: 7 [56320/60000 (94%)]\tLoss: -28.903488\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: -28.625496\n",
      "Train Epoch: 7 [58880/60000 (98%)]\tLoss: -29.150011\n",
      "====> Epoch: 7 Average loss: -28.8608\n",
      "====> Test set loss: -29.1683\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: -28.826210\n",
      "Train Epoch: 8 [1280/60000 (2%)]\tLoss: -28.842644\n",
      "Train Epoch: 8 [2560/60000 (4%)]\tLoss: -28.811981\n",
      "Train Epoch: 8 [3840/60000 (6%)]\tLoss: -28.452930\n",
      "Train Epoch: 8 [5120/60000 (9%)]\tLoss: -29.270706\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: -29.035088\n",
      "Train Epoch: 8 [7680/60000 (13%)]\tLoss: -28.838043\n",
      "Train Epoch: 8 [8960/60000 (15%)]\tLoss: -29.060608\n",
      "Train Epoch: 8 [10240/60000 (17%)]\tLoss: -29.173378\n",
      "Train Epoch: 8 [11520/60000 (19%)]\tLoss: -28.923922\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: -28.584194\n",
      "Train Epoch: 8 [14080/60000 (23%)]\tLoss: -28.593344\n",
      "Train Epoch: 8 [15360/60000 (26%)]\tLoss: -28.515900\n",
      "Train Epoch: 8 [16640/60000 (28%)]\tLoss: -28.628555\n",
      "Train Epoch: 8 [17920/60000 (30%)]\tLoss: -28.814659\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: -28.719112\n",
      "Train Epoch: 8 [20480/60000 (34%)]\tLoss: -28.827185\n",
      "Train Epoch: 8 [21760/60000 (36%)]\tLoss: -29.028301\n",
      "Train Epoch: 8 [23040/60000 (38%)]\tLoss: -29.007757\n",
      "Train Epoch: 8 [24320/60000 (41%)]\tLoss: -29.078625\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: -29.039022\n",
      "Train Epoch: 8 [26880/60000 (45%)]\tLoss: -28.820906\n",
      "Train Epoch: 8 [28160/60000 (47%)]\tLoss: -28.441242\n",
      "Train Epoch: 8 [29440/60000 (49%)]\tLoss: -28.953438\n",
      "Train Epoch: 8 [30720/60000 (51%)]\tLoss: -28.805180\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: -28.827024\n",
      "Train Epoch: 8 [33280/60000 (55%)]\tLoss: -28.735809\n",
      "Train Epoch: 8 [34560/60000 (58%)]\tLoss: -28.801401\n",
      "Train Epoch: 8 [35840/60000 (60%)]\tLoss: -28.684227\n",
      "Train Epoch: 8 [37120/60000 (62%)]\tLoss: -28.889757\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: -28.631281\n",
      "Train Epoch: 8 [39680/60000 (66%)]\tLoss: -28.691486\n",
      "Train Epoch: 8 [40960/60000 (68%)]\tLoss: -28.976471\n",
      "Train Epoch: 8 [42240/60000 (70%)]\tLoss: -28.850206\n",
      "Train Epoch: 8 [43520/60000 (72%)]\tLoss: -28.851465\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: -28.748386\n",
      "Train Epoch: 8 [46080/60000 (77%)]\tLoss: -28.906509\n",
      "Train Epoch: 8 [47360/60000 (79%)]\tLoss: -28.878151\n",
      "Train Epoch: 8 [48640/60000 (81%)]\tLoss: -29.248835\n",
      "Train Epoch: 8 [49920/60000 (83%)]\tLoss: -29.299986\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: -29.147053\n",
      "Train Epoch: 8 [52480/60000 (87%)]\tLoss: -28.456690\n",
      "Train Epoch: 8 [53760/60000 (90%)]\tLoss: -29.057598\n",
      "Train Epoch: 8 [55040/60000 (92%)]\tLoss: -28.666864\n",
      "Train Epoch: 8 [56320/60000 (94%)]\tLoss: -28.782185\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: -28.770880\n",
      "Train Epoch: 8 [58880/60000 (98%)]\tLoss: -28.944502\n",
      "====> Epoch: 8 Average loss: -28.8421\n",
      "====> Test set loss: -29.2137\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: -28.802471\n",
      "Train Epoch: 9 [1280/60000 (2%)]\tLoss: -28.617805\n",
      "Train Epoch: 9 [2560/60000 (4%)]\tLoss: -28.894672\n",
      "Train Epoch: 9 [3840/60000 (6%)]\tLoss: -28.568880\n",
      "Train Epoch: 9 [5120/60000 (9%)]\tLoss: -28.466864\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: -28.766136\n",
      "Train Epoch: 9 [7680/60000 (13%)]\tLoss: -28.569931\n",
      "Train Epoch: 9 [8960/60000 (15%)]\tLoss: -28.640732\n",
      "Train Epoch: 9 [10240/60000 (17%)]\tLoss: -28.824429\n",
      "Train Epoch: 9 [11520/60000 (19%)]\tLoss: -28.747465\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: -29.040539\n",
      "Train Epoch: 9 [14080/60000 (23%)]\tLoss: -28.936012\n",
      "Train Epoch: 9 [15360/60000 (26%)]\tLoss: -28.932701\n",
      "Train Epoch: 9 [16640/60000 (28%)]\tLoss: -28.855419\n",
      "Train Epoch: 9 [17920/60000 (30%)]\tLoss: -29.189373\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: -29.080193\n",
      "Train Epoch: 9 [20480/60000 (34%)]\tLoss: -28.893496\n",
      "Train Epoch: 9 [21760/60000 (36%)]\tLoss: -28.766088\n",
      "Train Epoch: 9 [23040/60000 (38%)]\tLoss: -28.878712\n",
      "Train Epoch: 9 [24320/60000 (41%)]\tLoss: -29.077744\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: -28.765104\n",
      "Train Epoch: 9 [26880/60000 (45%)]\tLoss: -29.206139\n",
      "Train Epoch: 9 [28160/60000 (47%)]\tLoss: -29.047085\n",
      "Train Epoch: 9 [29440/60000 (49%)]\tLoss: -28.876080\n",
      "Train Epoch: 9 [30720/60000 (51%)]\tLoss: -28.984255\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: -28.999247\n",
      "Train Epoch: 9 [33280/60000 (55%)]\tLoss: -28.751974\n",
      "Train Epoch: 9 [34560/60000 (58%)]\tLoss: -28.967209\n",
      "Train Epoch: 9 [35840/60000 (60%)]\tLoss: -29.175774\n",
      "Train Epoch: 9 [37120/60000 (62%)]\tLoss: -28.871231\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: -28.934555\n",
      "Train Epoch: 9 [39680/60000 (66%)]\tLoss: -29.221148\n",
      "Train Epoch: 9 [40960/60000 (68%)]\tLoss: -29.226805\n",
      "Train Epoch: 9 [42240/60000 (70%)]\tLoss: -28.723106\n",
      "Train Epoch: 9 [43520/60000 (72%)]\tLoss: -28.939098\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: -28.899717\n",
      "Train Epoch: 9 [46080/60000 (77%)]\tLoss: -28.730438\n",
      "Train Epoch: 9 [47360/60000 (79%)]\tLoss: -29.056644\n",
      "Train Epoch: 9 [48640/60000 (81%)]\tLoss: -29.071196\n",
      "Train Epoch: 9 [49920/60000 (83%)]\tLoss: -29.157364\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: -29.108381\n",
      "Train Epoch: 9 [52480/60000 (87%)]\tLoss: -29.147734\n",
      "Train Epoch: 9 [53760/60000 (90%)]\tLoss: -29.133141\n",
      "Train Epoch: 9 [55040/60000 (92%)]\tLoss: -29.041466\n",
      "Train Epoch: 9 [56320/60000 (94%)]\tLoss: -28.980747\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: -29.141047\n",
      "Train Epoch: 9 [58880/60000 (98%)]\tLoss: -28.784245\n",
      "====> Epoch: 9 Average loss: -28.9449\n",
      "====> Test set loss: -29.4351\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: -29.021818\n",
      "Train Epoch: 10 [1280/60000 (2%)]\tLoss: -28.854416\n",
      "Train Epoch: 10 [2560/60000 (4%)]\tLoss: -29.263779\n",
      "Train Epoch: 10 [3840/60000 (6%)]\tLoss: -29.210117\n",
      "Train Epoch: 10 [5120/60000 (9%)]\tLoss: -29.022333\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: -28.756075\n",
      "Train Epoch: 10 [7680/60000 (13%)]\tLoss: -28.992088\n",
      "Train Epoch: 10 [8960/60000 (15%)]\tLoss: -28.869411\n",
      "Train Epoch: 10 [10240/60000 (17%)]\tLoss: -28.798962\n",
      "Train Epoch: 10 [11520/60000 (19%)]\tLoss: -28.741919\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: -29.045334\n",
      "Train Epoch: 10 [14080/60000 (23%)]\tLoss: -28.897329\n",
      "Train Epoch: 10 [15360/60000 (26%)]\tLoss: -29.099649\n",
      "Train Epoch: 10 [16640/60000 (28%)]\tLoss: -28.992788\n",
      "Train Epoch: 10 [17920/60000 (30%)]\tLoss: -28.766281\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: -29.160948\n",
      "Train Epoch: 10 [20480/60000 (34%)]\tLoss: -29.050228\n",
      "Train Epoch: 10 [21760/60000 (36%)]\tLoss: -29.264324\n",
      "Train Epoch: 10 [23040/60000 (38%)]\tLoss: -29.362310\n",
      "Train Epoch: 10 [24320/60000 (41%)]\tLoss: -29.501476\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: -29.222948\n",
      "Train Epoch: 10 [26880/60000 (45%)]\tLoss: -28.988413\n",
      "Train Epoch: 10 [28160/60000 (47%)]\tLoss: -28.846653\n",
      "Train Epoch: 10 [29440/60000 (49%)]\tLoss: -28.963955\n",
      "Train Epoch: 10 [30720/60000 (51%)]\tLoss: -29.254467\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: -29.036421\n",
      "Train Epoch: 10 [33280/60000 (55%)]\tLoss: -29.105137\n",
      "Train Epoch: 10 [34560/60000 (58%)]\tLoss: -29.096798\n",
      "Train Epoch: 10 [35840/60000 (60%)]\tLoss: -28.952282\n",
      "Train Epoch: 10 [37120/60000 (62%)]\tLoss: -29.146091\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: -29.018522\n",
      "Train Epoch: 10 [39680/60000 (66%)]\tLoss: -28.924078\n",
      "Train Epoch: 10 [40960/60000 (68%)]\tLoss: -29.246746\n",
      "Train Epoch: 10 [42240/60000 (70%)]\tLoss: -29.236425\n",
      "Train Epoch: 10 [43520/60000 (72%)]\tLoss: -29.021193\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: -29.166977\n",
      "Train Epoch: 10 [46080/60000 (77%)]\tLoss: -29.011293\n",
      "Train Epoch: 10 [47360/60000 (79%)]\tLoss: -29.068169\n",
      "Train Epoch: 10 [48640/60000 (81%)]\tLoss: -29.078316\n",
      "Train Epoch: 10 [49920/60000 (83%)]\tLoss: -28.936537\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: -29.005888\n",
      "Train Epoch: 10 [52480/60000 (87%)]\tLoss: -28.976624\n",
      "Train Epoch: 10 [53760/60000 (90%)]\tLoss: -28.566689\n",
      "Train Epoch: 10 [55040/60000 (92%)]\tLoss: -29.018072\n",
      "Train Epoch: 10 [56320/60000 (94%)]\tLoss: -28.947533\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: -29.145788\n",
      "Train Epoch: 10 [58880/60000 (98%)]\tLoss: -28.689541\n",
      "====> Epoch: 10 Average loss: -29.0902\n",
      "====> Test set loss: -29.4298\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: -28.875004\n",
      "Train Epoch: 11 [1280/60000 (2%)]\tLoss: -28.498003\n",
      "Train Epoch: 11 [2560/60000 (4%)]\tLoss: -28.851522\n",
      "Train Epoch: 11 [3840/60000 (6%)]\tLoss: -28.743740\n",
      "Train Epoch: 11 [5120/60000 (9%)]\tLoss: -29.027233\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: -29.143896\n",
      "Train Epoch: 11 [7680/60000 (13%)]\tLoss: -29.249207\n",
      "Train Epoch: 11 [8960/60000 (15%)]\tLoss: -29.143139\n",
      "Train Epoch: 11 [10240/60000 (17%)]\tLoss: -29.112890\n",
      "Train Epoch: 11 [11520/60000 (19%)]\tLoss: -29.077110\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: -28.763386\n",
      "Train Epoch: 11 [14080/60000 (23%)]\tLoss: -29.518532\n",
      "Train Epoch: 11 [15360/60000 (26%)]\tLoss: -29.314804\n",
      "Train Epoch: 11 [16640/60000 (28%)]\tLoss: -29.572807\n",
      "Train Epoch: 11 [17920/60000 (30%)]\tLoss: -29.275276\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: -29.431551\n",
      "Train Epoch: 11 [20480/60000 (34%)]\tLoss: -29.328808\n",
      "Train Epoch: 11 [21760/60000 (36%)]\tLoss: -28.987028\n",
      "Train Epoch: 11 [23040/60000 (38%)]\tLoss: -29.150341\n",
      "Train Epoch: 11 [24320/60000 (41%)]\tLoss: -29.124279\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: -29.254002\n",
      "Train Epoch: 11 [26880/60000 (45%)]\tLoss: -29.170561\n",
      "Train Epoch: 11 [28160/60000 (47%)]\tLoss: -28.957153\n",
      "Train Epoch: 11 [29440/60000 (49%)]\tLoss: -29.202629\n",
      "Train Epoch: 11 [30720/60000 (51%)]\tLoss: -29.309618\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: -29.379427\n",
      "Train Epoch: 11 [33280/60000 (55%)]\tLoss: -29.229136\n",
      "Train Epoch: 11 [34560/60000 (58%)]\tLoss: -29.509363\n",
      "Train Epoch: 11 [35840/60000 (60%)]\tLoss: -29.579800\n",
      "Train Epoch: 11 [37120/60000 (62%)]\tLoss: -28.974707\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: -28.915817\n",
      "Train Epoch: 11 [39680/60000 (66%)]\tLoss: -29.034571\n",
      "Train Epoch: 11 [40960/60000 (68%)]\tLoss: -28.993605\n",
      "Train Epoch: 11 [42240/60000 (70%)]\tLoss: -28.751673\n",
      "Train Epoch: 11 [43520/60000 (72%)]\tLoss: -29.304905\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: -29.390871\n",
      "Train Epoch: 11 [46080/60000 (77%)]\tLoss: -29.236588\n",
      "Train Epoch: 11 [47360/60000 (79%)]\tLoss: -29.322144\n",
      "Train Epoch: 11 [48640/60000 (81%)]\tLoss: -29.146612\n",
      "Train Epoch: 11 [49920/60000 (83%)]\tLoss: -29.425631\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: -28.969107\n",
      "Train Epoch: 11 [52480/60000 (87%)]\tLoss: -28.833164\n",
      "Train Epoch: 11 [53760/60000 (90%)]\tLoss: -29.016405\n",
      "Train Epoch: 11 [55040/60000 (92%)]\tLoss: -28.723011\n",
      "Train Epoch: 11 [56320/60000 (94%)]\tLoss: -29.240208\n",
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: -28.875723\n",
      "Train Epoch: 11 [58880/60000 (98%)]\tLoss: -29.444176\n",
      "====> Epoch: 11 Average loss: -29.1781\n",
      "====> Test set loss: -29.4374\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: -28.928709\n",
      "Train Epoch: 12 [1280/60000 (2%)]\tLoss: -29.266174\n",
      "Train Epoch: 12 [2560/60000 (4%)]\tLoss: -29.206205\n",
      "Train Epoch: 12 [3840/60000 (6%)]\tLoss: -29.222721\n",
      "Train Epoch: 12 [5120/60000 (9%)]\tLoss: -29.447823\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: -29.377596\n",
      "Train Epoch: 12 [7680/60000 (13%)]\tLoss: -28.786098\n",
      "Train Epoch: 12 [8960/60000 (15%)]\tLoss: -29.094227\n",
      "Train Epoch: 12 [10240/60000 (17%)]\tLoss: -29.616856\n",
      "Train Epoch: 12 [11520/60000 (19%)]\tLoss: -28.919447\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: -29.245176\n",
      "Train Epoch: 12 [14080/60000 (23%)]\tLoss: -28.993504\n",
      "Train Epoch: 12 [15360/60000 (26%)]\tLoss: -29.216309\n",
      "Train Epoch: 12 [16640/60000 (28%)]\tLoss: -29.225409\n",
      "Train Epoch: 12 [17920/60000 (30%)]\tLoss: -29.177122\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: -29.211885\n",
      "Train Epoch: 12 [20480/60000 (34%)]\tLoss: -29.521944\n",
      "Train Epoch: 12 [21760/60000 (36%)]\tLoss: -29.258802\n",
      "Train Epoch: 12 [23040/60000 (38%)]\tLoss: -29.140501\n",
      "Train Epoch: 12 [24320/60000 (41%)]\tLoss: -29.519255\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: -29.124525\n",
      "Train Epoch: 12 [26880/60000 (45%)]\tLoss: -29.061407\n",
      "Train Epoch: 12 [28160/60000 (47%)]\tLoss: -28.978966\n",
      "Train Epoch: 12 [29440/60000 (49%)]\tLoss: -29.214104\n",
      "Train Epoch: 12 [30720/60000 (51%)]\tLoss: -29.418499\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: -29.155228\n",
      "Train Epoch: 12 [33280/60000 (55%)]\tLoss: -29.121723\n",
      "Train Epoch: 12 [34560/60000 (58%)]\tLoss: -29.410053\n",
      "Train Epoch: 12 [35840/60000 (60%)]\tLoss: -29.334892\n",
      "Train Epoch: 12 [37120/60000 (62%)]\tLoss: -29.636078\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: -29.214235\n",
      "Train Epoch: 12 [39680/60000 (66%)]\tLoss: -29.558804\n",
      "Train Epoch: 12 [40960/60000 (68%)]\tLoss: -29.445911\n",
      "Train Epoch: 12 [42240/60000 (70%)]\tLoss: -29.266087\n",
      "Train Epoch: 12 [43520/60000 (72%)]\tLoss: -29.212965\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: -29.438635\n",
      "Train Epoch: 12 [46080/60000 (77%)]\tLoss: -28.977406\n",
      "Train Epoch: 12 [47360/60000 (79%)]\tLoss: -29.137665\n",
      "Train Epoch: 12 [48640/60000 (81%)]\tLoss: -29.024010\n",
      "Train Epoch: 12 [49920/60000 (83%)]\tLoss: -29.101990\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: -29.046566\n",
      "Train Epoch: 12 [52480/60000 (87%)]\tLoss: -29.614517\n",
      "Train Epoch: 12 [53760/60000 (90%)]\tLoss: -29.064034\n",
      "Train Epoch: 12 [55040/60000 (92%)]\tLoss: -29.344601\n",
      "Train Epoch: 12 [56320/60000 (94%)]\tLoss: -29.290266\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: -29.161716\n",
      "Train Epoch: 12 [58880/60000 (98%)]\tLoss: -29.566525\n",
      "====> Epoch: 12 Average loss: -29.2373\n",
      "====> Test set loss: -29.6019\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: -28.856279\n",
      "Train Epoch: 13 [1280/60000 (2%)]\tLoss: -29.482557\n",
      "Train Epoch: 13 [2560/60000 (4%)]\tLoss: -28.975349\n",
      "Train Epoch: 13 [3840/60000 (6%)]\tLoss: -29.214115\n",
      "Train Epoch: 13 [5120/60000 (9%)]\tLoss: -29.824455\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: -29.581177\n",
      "Train Epoch: 13 [7680/60000 (13%)]\tLoss: -29.350155\n",
      "Train Epoch: 13 [8960/60000 (15%)]\tLoss: -29.639372\n",
      "Train Epoch: 13 [10240/60000 (17%)]\tLoss: -29.537729\n",
      "Train Epoch: 13 [11520/60000 (19%)]\tLoss: -29.509418\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: -29.300301\n",
      "Train Epoch: 13 [14080/60000 (23%)]\tLoss: -29.113771\n",
      "Train Epoch: 13 [15360/60000 (26%)]\tLoss: -29.321178\n",
      "Train Epoch: 13 [16640/60000 (28%)]\tLoss: -28.911150\n",
      "Train Epoch: 13 [17920/60000 (30%)]\tLoss: -29.250345\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: -29.116714\n",
      "Train Epoch: 13 [20480/60000 (34%)]\tLoss: -29.258478\n",
      "Train Epoch: 13 [21760/60000 (36%)]\tLoss: -29.339342\n",
      "Train Epoch: 13 [23040/60000 (38%)]\tLoss: -29.215975\n",
      "Train Epoch: 13 [24320/60000 (41%)]\tLoss: -29.203083\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: -29.270555\n",
      "Train Epoch: 13 [26880/60000 (45%)]\tLoss: -29.724270\n",
      "Train Epoch: 13 [28160/60000 (47%)]\tLoss: -29.039598\n",
      "Train Epoch: 13 [29440/60000 (49%)]\tLoss: -29.182123\n",
      "Train Epoch: 13 [30720/60000 (51%)]\tLoss: -29.121613\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: -29.176626\n",
      "Train Epoch: 13 [33280/60000 (55%)]\tLoss: -28.446783\n",
      "Train Epoch: 13 [34560/60000 (58%)]\tLoss: -29.382738\n",
      "Train Epoch: 13 [35840/60000 (60%)]\tLoss: -29.249969\n",
      "Train Epoch: 13 [37120/60000 (62%)]\tLoss: -29.455711\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: -29.372854\n",
      "Train Epoch: 13 [39680/60000 (66%)]\tLoss: -28.923616\n",
      "Train Epoch: 13 [40960/60000 (68%)]\tLoss: -29.241402\n",
      "Train Epoch: 13 [42240/60000 (70%)]\tLoss: -29.173424\n",
      "Train Epoch: 13 [43520/60000 (72%)]\tLoss: -28.985260\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: -29.383442\n",
      "Train Epoch: 13 [46080/60000 (77%)]\tLoss: -29.369417\n",
      "Train Epoch: 13 [47360/60000 (79%)]\tLoss: -29.088690\n",
      "Train Epoch: 13 [48640/60000 (81%)]\tLoss: -29.417725\n",
      "Train Epoch: 13 [49920/60000 (83%)]\tLoss: -29.105524\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: -29.271692\n",
      "Train Epoch: 13 [52480/60000 (87%)]\tLoss: -29.611593\n",
      "Train Epoch: 13 [53760/60000 (90%)]\tLoss: -29.138054\n",
      "Train Epoch: 13 [55040/60000 (92%)]\tLoss: -29.163727\n",
      "Train Epoch: 13 [56320/60000 (94%)]\tLoss: -28.927204\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: -28.903761\n",
      "Train Epoch: 13 [58880/60000 (98%)]\tLoss: -29.043543\n",
      "====> Epoch: 13 Average loss: -29.2527\n",
      "====> Test set loss: -29.3681\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: -29.201616\n",
      "Train Epoch: 14 [1280/60000 (2%)]\tLoss: -29.224203\n",
      "Train Epoch: 14 [2560/60000 (4%)]\tLoss: -29.212847\n",
      "Train Epoch: 14 [3840/60000 (6%)]\tLoss: -29.227837\n",
      "Train Epoch: 14 [5120/60000 (9%)]\tLoss: -29.387756\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tLoss: -29.226091\n",
      "Train Epoch: 14 [7680/60000 (13%)]\tLoss: -29.093845\n",
      "Train Epoch: 14 [8960/60000 (15%)]\tLoss: -29.590960\n",
      "Train Epoch: 14 [10240/60000 (17%)]\tLoss: -29.551235\n",
      "Train Epoch: 14 [11520/60000 (19%)]\tLoss: -29.237385\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: -29.067938\n",
      "Train Epoch: 14 [14080/60000 (23%)]\tLoss: -29.124943\n",
      "Train Epoch: 14 [15360/60000 (26%)]\tLoss: -28.900055\n",
      "Train Epoch: 14 [16640/60000 (28%)]\tLoss: -29.410715\n",
      "Train Epoch: 14 [17920/60000 (30%)]\tLoss: -28.996029\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: -29.112415\n",
      "Train Epoch: 14 [20480/60000 (34%)]\tLoss: -29.243574\n",
      "Train Epoch: 14 [21760/60000 (36%)]\tLoss: -29.264711\n",
      "Train Epoch: 14 [23040/60000 (38%)]\tLoss: -28.980553\n",
      "Train Epoch: 14 [24320/60000 (41%)]\tLoss: -29.179472\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: -29.321089\n",
      "Train Epoch: 14 [26880/60000 (45%)]\tLoss: -29.481663\n",
      "Train Epoch: 14 [28160/60000 (47%)]\tLoss: -29.395962\n",
      "Train Epoch: 14 [29440/60000 (49%)]\tLoss: -29.148623\n",
      "Train Epoch: 14 [30720/60000 (51%)]\tLoss: -29.281614\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: -29.313095\n",
      "Train Epoch: 14 [33280/60000 (55%)]\tLoss: -29.218779\n",
      "Train Epoch: 14 [34560/60000 (58%)]\tLoss: -29.555305\n",
      "Train Epoch: 14 [35840/60000 (60%)]\tLoss: -29.605368\n",
      "Train Epoch: 14 [37120/60000 (62%)]\tLoss: -29.403791\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: -29.605518\n",
      "Train Epoch: 14 [39680/60000 (66%)]\tLoss: -29.481176\n",
      "Train Epoch: 14 [40960/60000 (68%)]\tLoss: -29.473917\n",
      "Train Epoch: 14 [42240/60000 (70%)]\tLoss: -29.277756\n",
      "Train Epoch: 14 [43520/60000 (72%)]\tLoss: -29.071411\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: -29.293339\n",
      "Train Epoch: 14 [46080/60000 (77%)]\tLoss: -29.325439\n",
      "Train Epoch: 14 [47360/60000 (79%)]\tLoss: -29.894989\n",
      "Train Epoch: 14 [48640/60000 (81%)]\tLoss: -29.471825\n",
      "Train Epoch: 14 [49920/60000 (83%)]\tLoss: -29.194326\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: -29.200302\n",
      "Train Epoch: 14 [52480/60000 (87%)]\tLoss: -29.440006\n",
      "Train Epoch: 14 [53760/60000 (90%)]\tLoss: -29.163036\n",
      "Train Epoch: 14 [55040/60000 (92%)]\tLoss: -29.312033\n",
      "Train Epoch: 14 [56320/60000 (94%)]\tLoss: -29.111929\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: -29.310869\n",
      "Train Epoch: 14 [58880/60000 (98%)]\tLoss: -29.403961\n",
      "====> Epoch: 14 Average loss: -29.3146\n",
      "====> Test set loss: -29.6716\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: -29.492874\n",
      "Train Epoch: 15 [1280/60000 (2%)]\tLoss: -29.419598\n",
      "Train Epoch: 15 [2560/60000 (4%)]\tLoss: -29.378614\n",
      "Train Epoch: 15 [3840/60000 (6%)]\tLoss: -29.381838\n",
      "Train Epoch: 15 [5120/60000 (9%)]\tLoss: -29.567434\n",
      "Train Epoch: 15 [6400/60000 (11%)]\tLoss: -29.541523\n",
      "Train Epoch: 15 [7680/60000 (13%)]\tLoss: -29.295347\n",
      "Train Epoch: 15 [8960/60000 (15%)]\tLoss: -29.476027\n",
      "Train Epoch: 15 [10240/60000 (17%)]\tLoss: -29.953098\n",
      "Train Epoch: 15 [11520/60000 (19%)]\tLoss: -29.122900\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: -29.302740\n",
      "Train Epoch: 15 [14080/60000 (23%)]\tLoss: -29.477665\n",
      "Train Epoch: 15 [15360/60000 (26%)]\tLoss: -29.344448\n",
      "Train Epoch: 15 [16640/60000 (28%)]\tLoss: -29.576822\n",
      "Train Epoch: 15 [17920/60000 (30%)]\tLoss: -29.614382\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: -29.345047\n",
      "Train Epoch: 15 [20480/60000 (34%)]\tLoss: -29.431694\n",
      "Train Epoch: 15 [21760/60000 (36%)]\tLoss: -29.881487\n",
      "Train Epoch: 15 [23040/60000 (38%)]\tLoss: -29.741838\n",
      "Train Epoch: 15 [24320/60000 (41%)]\tLoss: -29.589924\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: -29.796232\n",
      "Train Epoch: 15 [26880/60000 (45%)]\tLoss: -29.489235\n",
      "Train Epoch: 15 [28160/60000 (47%)]\tLoss: -29.900635\n",
      "Train Epoch: 15 [29440/60000 (49%)]\tLoss: -29.321415\n",
      "Train Epoch: 15 [30720/60000 (51%)]\tLoss: -29.578398\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: -29.942472\n",
      "Train Epoch: 15 [33280/60000 (55%)]\tLoss: -29.466881\n",
      "Train Epoch: 15 [34560/60000 (58%)]\tLoss: -29.596926\n",
      "Train Epoch: 15 [35840/60000 (60%)]\tLoss: -29.381298\n",
      "Train Epoch: 15 [37120/60000 (62%)]\tLoss: -29.550024\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: -29.469185\n",
      "Train Epoch: 15 [39680/60000 (66%)]\tLoss: -29.242962\n",
      "Train Epoch: 15 [40960/60000 (68%)]\tLoss: -29.196806\n",
      "Train Epoch: 15 [42240/60000 (70%)]\tLoss: -29.435713\n",
      "Train Epoch: 15 [43520/60000 (72%)]\tLoss: -29.408463\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tLoss: -29.276628\n",
      "Train Epoch: 15 [46080/60000 (77%)]\tLoss: -29.706564\n",
      "Train Epoch: 15 [47360/60000 (79%)]\tLoss: -29.832998\n",
      "Train Epoch: 15 [48640/60000 (81%)]\tLoss: -29.309315\n",
      "Train Epoch: 15 [49920/60000 (83%)]\tLoss: -29.226545\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: -29.515533\n",
      "Train Epoch: 15 [52480/60000 (87%)]\tLoss: -29.396799\n",
      "Train Epoch: 15 [53760/60000 (90%)]\tLoss: -29.299284\n",
      "Train Epoch: 15 [55040/60000 (92%)]\tLoss: -29.386728\n",
      "Train Epoch: 15 [56320/60000 (94%)]\tLoss: -29.244387\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: -29.436558\n",
      "Train Epoch: 15 [58880/60000 (98%)]\tLoss: -29.438757\n",
      "====> Epoch: 15 Average loss: -29.4916\n",
      "====> Test set loss: -29.6651\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: -28.874416\n",
      "Train Epoch: 16 [1280/60000 (2%)]\tLoss: -29.727999\n",
      "Train Epoch: 16 [2560/60000 (4%)]\tLoss: -29.465553\n",
      "Train Epoch: 16 [3840/60000 (6%)]\tLoss: -29.466484\n",
      "Train Epoch: 16 [5120/60000 (9%)]\tLoss: -29.388002\n",
      "Train Epoch: 16 [6400/60000 (11%)]\tLoss: -29.437750\n",
      "Train Epoch: 16 [7680/60000 (13%)]\tLoss: -29.582581\n",
      "Train Epoch: 16 [8960/60000 (15%)]\tLoss: -29.221272\n",
      "Train Epoch: 16 [10240/60000 (17%)]\tLoss: -28.963585\n",
      "Train Epoch: 16 [11520/60000 (19%)]\tLoss: -29.352320\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: -29.556515\n",
      "Train Epoch: 16 [14080/60000 (23%)]\tLoss: -29.193090\n",
      "Train Epoch: 16 [15360/60000 (26%)]\tLoss: -29.598877\n",
      "Train Epoch: 16 [16640/60000 (28%)]\tLoss: -29.829887\n",
      "Train Epoch: 16 [17920/60000 (30%)]\tLoss: -29.523998\n",
      "Train Epoch: 16 [19200/60000 (32%)]\tLoss: -29.373758\n",
      "Train Epoch: 16 [20480/60000 (34%)]\tLoss: -29.212740\n",
      "Train Epoch: 16 [21760/60000 (36%)]\tLoss: -29.166224\n",
      "Train Epoch: 16 [23040/60000 (38%)]\tLoss: -29.835882\n",
      "Train Epoch: 16 [24320/60000 (41%)]\tLoss: -29.915129\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: -29.120096\n",
      "Train Epoch: 16 [26880/60000 (45%)]\tLoss: -29.310579\n",
      "Train Epoch: 16 [28160/60000 (47%)]\tLoss: -29.228111\n",
      "Train Epoch: 16 [29440/60000 (49%)]\tLoss: -29.391321\n",
      "Train Epoch: 16 [30720/60000 (51%)]\tLoss: -29.305883\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: -28.999786\n",
      "Train Epoch: 16 [33280/60000 (55%)]\tLoss: -29.467318\n",
      "Train Epoch: 16 [34560/60000 (58%)]\tLoss: -29.481936\n",
      "Train Epoch: 16 [35840/60000 (60%)]\tLoss: -29.104170\n",
      "Train Epoch: 16 [37120/60000 (62%)]\tLoss: -29.664248\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: -29.400976\n",
      "Train Epoch: 16 [39680/60000 (66%)]\tLoss: -29.383427\n",
      "Train Epoch: 16 [40960/60000 (68%)]\tLoss: -29.288267\n",
      "Train Epoch: 16 [42240/60000 (70%)]\tLoss: -29.302734\n",
      "Train Epoch: 16 [43520/60000 (72%)]\tLoss: -29.337234\n",
      "Train Epoch: 16 [44800/60000 (75%)]\tLoss: -29.749535\n",
      "Train Epoch: 16 [46080/60000 (77%)]\tLoss: -29.461847\n",
      "Train Epoch: 16 [47360/60000 (79%)]\tLoss: -29.322084\n",
      "Train Epoch: 16 [48640/60000 (81%)]\tLoss: -29.102764\n",
      "Train Epoch: 16 [49920/60000 (83%)]\tLoss: -29.297371\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: -29.625210\n",
      "Train Epoch: 16 [52480/60000 (87%)]\tLoss: -29.628178\n",
      "Train Epoch: 16 [53760/60000 (90%)]\tLoss: -29.486521\n",
      "Train Epoch: 16 [55040/60000 (92%)]\tLoss: -29.494064\n",
      "Train Epoch: 16 [56320/60000 (94%)]\tLoss: -29.508829\n",
      "Train Epoch: 16 [57600/60000 (96%)]\tLoss: -29.709944\n",
      "Train Epoch: 16 [58880/60000 (98%)]\tLoss: -29.595984\n",
      "====> Epoch: 16 Average loss: -29.4685\n",
      "====> Test set loss: -29.8493\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: -29.601793\n",
      "Train Epoch: 17 [1280/60000 (2%)]\tLoss: -29.420948\n",
      "Train Epoch: 17 [2560/60000 (4%)]\tLoss: -29.939354\n",
      "Train Epoch: 17 [3840/60000 (6%)]\tLoss: -29.600821\n",
      "Train Epoch: 17 [5120/60000 (9%)]\tLoss: -29.343006\n",
      "Train Epoch: 17 [6400/60000 (11%)]\tLoss: -29.352240\n",
      "Train Epoch: 17 [7680/60000 (13%)]\tLoss: -29.152334\n",
      "Train Epoch: 17 [8960/60000 (15%)]\tLoss: -28.962238\n",
      "Train Epoch: 17 [10240/60000 (17%)]\tLoss: -29.200651\n",
      "Train Epoch: 17 [11520/60000 (19%)]\tLoss: -29.556791\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: -29.331869\n",
      "Train Epoch: 17 [14080/60000 (23%)]\tLoss: -29.510494\n",
      "Train Epoch: 17 [15360/60000 (26%)]\tLoss: -29.561983\n",
      "Train Epoch: 17 [16640/60000 (28%)]\tLoss: -29.301182\n",
      "Train Epoch: 17 [17920/60000 (30%)]\tLoss: -29.001305\n",
      "Train Epoch: 17 [19200/60000 (32%)]\tLoss: -29.460892\n",
      "Train Epoch: 17 [20480/60000 (34%)]\tLoss: -29.147800\n",
      "Train Epoch: 17 [21760/60000 (36%)]\tLoss: -29.224377\n",
      "Train Epoch: 17 [23040/60000 (38%)]\tLoss: -29.301956\n",
      "Train Epoch: 17 [24320/60000 (41%)]\tLoss: -29.118490\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: -29.272791\n",
      "Train Epoch: 17 [26880/60000 (45%)]\tLoss: -29.548071\n",
      "Train Epoch: 17 [28160/60000 (47%)]\tLoss: -29.376242\n",
      "Train Epoch: 17 [29440/60000 (49%)]\tLoss: -29.401867\n",
      "Train Epoch: 17 [30720/60000 (51%)]\tLoss: -28.728401\n",
      "Train Epoch: 17 [32000/60000 (53%)]\tLoss: -29.751589\n",
      "Train Epoch: 17 [33280/60000 (55%)]\tLoss: -29.497786\n",
      "Train Epoch: 17 [34560/60000 (58%)]\tLoss: -29.428862\n",
      "Train Epoch: 17 [35840/60000 (60%)]\tLoss: -29.148529\n",
      "Train Epoch: 17 [37120/60000 (62%)]\tLoss: -29.254545\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: -29.249336\n",
      "Train Epoch: 17 [39680/60000 (66%)]\tLoss: -29.304758\n",
      "Train Epoch: 17 [40960/60000 (68%)]\tLoss: -29.432650\n",
      "Train Epoch: 17 [42240/60000 (70%)]\tLoss: -29.419222\n",
      "Train Epoch: 17 [43520/60000 (72%)]\tLoss: -29.438471\n",
      "Train Epoch: 17 [44800/60000 (75%)]\tLoss: -29.431292\n",
      "Train Epoch: 17 [46080/60000 (77%)]\tLoss: -29.276093\n",
      "Train Epoch: 17 [47360/60000 (79%)]\tLoss: -29.314632\n",
      "Train Epoch: 17 [48640/60000 (81%)]\tLoss: -29.176773\n",
      "Train Epoch: 17 [49920/60000 (83%)]\tLoss: -29.348402\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: -29.305645\n",
      "Train Epoch: 17 [52480/60000 (87%)]\tLoss: -28.994865\n",
      "Train Epoch: 17 [53760/60000 (90%)]\tLoss: -29.311058\n",
      "Train Epoch: 17 [55040/60000 (92%)]\tLoss: -29.224665\n",
      "Train Epoch: 17 [56320/60000 (94%)]\tLoss: -29.337950\n",
      "Train Epoch: 17 [57600/60000 (96%)]\tLoss: -29.037138\n",
      "Train Epoch: 17 [58880/60000 (98%)]\tLoss: -29.187401\n",
      "====> Epoch: 17 Average loss: -29.3749\n",
      "====> Test set loss: -29.6252\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: -29.360540\n",
      "Train Epoch: 18 [1280/60000 (2%)]\tLoss: -29.275633\n",
      "Train Epoch: 18 [2560/60000 (4%)]\tLoss: -29.603315\n",
      "Train Epoch: 18 [3840/60000 (6%)]\tLoss: -29.458576\n",
      "Train Epoch: 18 [5120/60000 (9%)]\tLoss: -29.562418\n",
      "Train Epoch: 18 [6400/60000 (11%)]\tLoss: -29.166788\n",
      "Train Epoch: 18 [7680/60000 (13%)]\tLoss: -29.312702\n",
      "Train Epoch: 18 [8960/60000 (15%)]\tLoss: -29.666265\n",
      "Train Epoch: 18 [10240/60000 (17%)]\tLoss: -29.276625\n",
      "Train Epoch: 18 [11520/60000 (19%)]\tLoss: -29.021835\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: -29.525612\n",
      "Train Epoch: 18 [14080/60000 (23%)]\tLoss: -29.655998\n",
      "Train Epoch: 18 [15360/60000 (26%)]\tLoss: -29.268085\n",
      "Train Epoch: 18 [16640/60000 (28%)]\tLoss: -29.631033\n",
      "Train Epoch: 18 [17920/60000 (30%)]\tLoss: -29.654345\n",
      "Train Epoch: 18 [19200/60000 (32%)]\tLoss: -29.413448\n",
      "Train Epoch: 18 [20480/60000 (34%)]\tLoss: -29.733133\n",
      "Train Epoch: 18 [21760/60000 (36%)]\tLoss: -29.576223\n",
      "Train Epoch: 18 [23040/60000 (38%)]\tLoss: -29.489021\n",
      "Train Epoch: 18 [24320/60000 (41%)]\tLoss: -29.340635\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: -29.177473\n",
      "Train Epoch: 18 [26880/60000 (45%)]\tLoss: -29.708063\n",
      "Train Epoch: 18 [28160/60000 (47%)]\tLoss: -29.384941\n",
      "Train Epoch: 18 [29440/60000 (49%)]\tLoss: -29.426853\n",
      "Train Epoch: 18 [30720/60000 (51%)]\tLoss: -29.255569\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tLoss: -29.516096\n",
      "Train Epoch: 18 [33280/60000 (55%)]\tLoss: -29.276331\n",
      "Train Epoch: 18 [34560/60000 (58%)]\tLoss: -29.611921\n",
      "Train Epoch: 18 [35840/60000 (60%)]\tLoss: -29.655491\n",
      "Train Epoch: 18 [37120/60000 (62%)]\tLoss: -29.662415\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: -29.635565\n",
      "Train Epoch: 18 [39680/60000 (66%)]\tLoss: -29.699825\n",
      "Train Epoch: 18 [40960/60000 (68%)]\tLoss: -29.215425\n",
      "Train Epoch: 18 [42240/60000 (70%)]\tLoss: -29.778818\n",
      "Train Epoch: 18 [43520/60000 (72%)]\tLoss: -29.292273\n",
      "Train Epoch: 18 [44800/60000 (75%)]\tLoss: -29.585283\n",
      "Train Epoch: 18 [46080/60000 (77%)]\tLoss: -29.186449\n",
      "Train Epoch: 18 [47360/60000 (79%)]\tLoss: -28.882294\n",
      "Train Epoch: 18 [48640/60000 (81%)]\tLoss: -28.720455\n",
      "Train Epoch: 18 [49920/60000 (83%)]\tLoss: -28.866640\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: -29.271589\n",
      "Train Epoch: 18 [52480/60000 (87%)]\tLoss: -29.231335\n",
      "Train Epoch: 18 [53760/60000 (90%)]\tLoss: -29.188782\n",
      "Train Epoch: 18 [55040/60000 (92%)]\tLoss: -29.218220\n",
      "Train Epoch: 18 [56320/60000 (94%)]\tLoss: -29.536585\n",
      "Train Epoch: 18 [57600/60000 (96%)]\tLoss: -29.419895\n",
      "Train Epoch: 18 [58880/60000 (98%)]\tLoss: -29.478193\n",
      "====> Epoch: 18 Average loss: -29.4364\n",
      "====> Test set loss: -29.7152\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: -29.106287\n",
      "Train Epoch: 19 [1280/60000 (2%)]\tLoss: -29.570553\n",
      "Train Epoch: 19 [2560/60000 (4%)]\tLoss: -29.324238\n",
      "Train Epoch: 19 [3840/60000 (6%)]\tLoss: -29.342625\n",
      "Train Epoch: 19 [5120/60000 (9%)]\tLoss: -29.633963\n",
      "Train Epoch: 19 [6400/60000 (11%)]\tLoss: -29.489298\n",
      "Train Epoch: 19 [7680/60000 (13%)]\tLoss: -29.611164\n",
      "Train Epoch: 19 [8960/60000 (15%)]\tLoss: -29.719379\n",
      "Train Epoch: 19 [10240/60000 (17%)]\tLoss: -29.346844\n",
      "Train Epoch: 19 [11520/60000 (19%)]\tLoss: -29.604057\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: -29.341743\n",
      "Train Epoch: 19 [14080/60000 (23%)]\tLoss: -29.523335\n",
      "Train Epoch: 19 [15360/60000 (26%)]\tLoss: -29.557724\n",
      "Train Epoch: 19 [16640/60000 (28%)]\tLoss: -29.512318\n",
      "Train Epoch: 19 [17920/60000 (30%)]\tLoss: -29.652046\n",
      "Train Epoch: 19 [19200/60000 (32%)]\tLoss: -29.249496\n",
      "Train Epoch: 19 [20480/60000 (34%)]\tLoss: -29.309036\n",
      "Train Epoch: 19 [21760/60000 (36%)]\tLoss: -29.493912\n",
      "Train Epoch: 19 [23040/60000 (38%)]\tLoss: -29.115900\n",
      "Train Epoch: 19 [24320/60000 (41%)]\tLoss: -29.491339\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: -29.770163\n",
      "Train Epoch: 19 [26880/60000 (45%)]\tLoss: -29.270544\n",
      "Train Epoch: 19 [28160/60000 (47%)]\tLoss: -29.908224\n",
      "Train Epoch: 19 [29440/60000 (49%)]\tLoss: -29.609694\n",
      "Train Epoch: 19 [30720/60000 (51%)]\tLoss: -29.484438\n",
      "Train Epoch: 19 [32000/60000 (53%)]\tLoss: -29.788311\n",
      "Train Epoch: 19 [33280/60000 (55%)]\tLoss: -29.802185\n",
      "Train Epoch: 19 [34560/60000 (58%)]\tLoss: -29.218378\n",
      "Train Epoch: 19 [35840/60000 (60%)]\tLoss: -29.340023\n",
      "Train Epoch: 19 [37120/60000 (62%)]\tLoss: -29.362480\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: -29.732561\n",
      "Train Epoch: 19 [39680/60000 (66%)]\tLoss: -29.678263\n",
      "Train Epoch: 19 [40960/60000 (68%)]\tLoss: -29.995890\n",
      "Train Epoch: 19 [42240/60000 (70%)]\tLoss: -29.418924\n",
      "Train Epoch: 19 [43520/60000 (72%)]\tLoss: -29.619572\n",
      "Train Epoch: 19 [44800/60000 (75%)]\tLoss: -29.401989\n",
      "Train Epoch: 19 [46080/60000 (77%)]\tLoss: -29.477636\n",
      "Train Epoch: 19 [47360/60000 (79%)]\tLoss: -29.494917\n",
      "Train Epoch: 19 [48640/60000 (81%)]\tLoss: -29.692373\n",
      "Train Epoch: 19 [49920/60000 (83%)]\tLoss: -29.627966\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: -29.443775\n",
      "Train Epoch: 19 [52480/60000 (87%)]\tLoss: -28.995827\n",
      "Train Epoch: 19 [53760/60000 (90%)]\tLoss: -29.340588\n",
      "Train Epoch: 19 [55040/60000 (92%)]\tLoss: -29.405338\n",
      "Train Epoch: 19 [56320/60000 (94%)]\tLoss: -29.743893\n",
      "Train Epoch: 19 [57600/60000 (96%)]\tLoss: -29.752399\n",
      "Train Epoch: 19 [58880/60000 (98%)]\tLoss: -29.427952\n",
      "====> Epoch: 19 Average loss: -29.5063\n",
      "====> Test set loss: -29.9753\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: -29.887329\n",
      "Train Epoch: 20 [1280/60000 (2%)]\tLoss: -29.520723\n",
      "Train Epoch: 20 [2560/60000 (4%)]\tLoss: -29.106169\n",
      "Train Epoch: 20 [3840/60000 (6%)]\tLoss: -29.650320\n",
      "Train Epoch: 20 [5120/60000 (9%)]\tLoss: -29.771078\n",
      "Train Epoch: 20 [6400/60000 (11%)]\tLoss: -29.634691\n",
      "Train Epoch: 20 [7680/60000 (13%)]\tLoss: -29.252748\n",
      "Train Epoch: 20 [8960/60000 (15%)]\tLoss: -29.588690\n",
      "Train Epoch: 20 [10240/60000 (17%)]\tLoss: -29.488546\n",
      "Train Epoch: 20 [11520/60000 (19%)]\tLoss: -29.742828\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: -29.732637\n",
      "Train Epoch: 20 [14080/60000 (23%)]\tLoss: -29.772455\n",
      "Train Epoch: 20 [15360/60000 (26%)]\tLoss: -29.694971\n",
      "Train Epoch: 20 [16640/60000 (28%)]\tLoss: -29.514278\n",
      "Train Epoch: 20 [17920/60000 (30%)]\tLoss: -29.937799\n",
      "Train Epoch: 20 [19200/60000 (32%)]\tLoss: -29.886330\n",
      "Train Epoch: 20 [20480/60000 (34%)]\tLoss: -29.875439\n",
      "Train Epoch: 20 [21760/60000 (36%)]\tLoss: -29.526138\n",
      "Train Epoch: 20 [23040/60000 (38%)]\tLoss: -29.611988\n",
      "Train Epoch: 20 [24320/60000 (41%)]\tLoss: -29.419270\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: -29.183405\n",
      "Train Epoch: 20 [26880/60000 (45%)]\tLoss: -28.925474\n",
      "Train Epoch: 20 [28160/60000 (47%)]\tLoss: -29.340380\n",
      "Train Epoch: 20 [29440/60000 (49%)]\tLoss: -29.736197\n",
      "Train Epoch: 20 [30720/60000 (51%)]\tLoss: -29.439592\n",
      "Train Epoch: 20 [32000/60000 (53%)]\tLoss: -29.463976\n",
      "Train Epoch: 20 [33280/60000 (55%)]\tLoss: -29.699348\n",
      "Train Epoch: 20 [34560/60000 (58%)]\tLoss: -29.664110\n",
      "Train Epoch: 20 [35840/60000 (60%)]\tLoss: -29.595407\n",
      "Train Epoch: 20 [37120/60000 (62%)]\tLoss: -29.961975\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: -29.860739\n",
      "Train Epoch: 20 [39680/60000 (66%)]\tLoss: -29.674931\n",
      "Train Epoch: 20 [40960/60000 (68%)]\tLoss: -29.577925\n",
      "Train Epoch: 20 [42240/60000 (70%)]\tLoss: -29.790564\n",
      "Train Epoch: 20 [43520/60000 (72%)]\tLoss: -29.020573\n",
      "Train Epoch: 20 [44800/60000 (75%)]\tLoss: -29.601542\n",
      "Train Epoch: 20 [46080/60000 (77%)]\tLoss: -29.729017\n",
      "Train Epoch: 20 [47360/60000 (79%)]\tLoss: -29.541439\n",
      "Train Epoch: 20 [48640/60000 (81%)]\tLoss: -29.595810\n",
      "Train Epoch: 20 [49920/60000 (83%)]\tLoss: -29.422071\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: -29.378950\n",
      "Train Epoch: 20 [52480/60000 (87%)]\tLoss: -29.317205\n",
      "Train Epoch: 20 [53760/60000 (90%)]\tLoss: -29.332027\n",
      "Train Epoch: 20 [55040/60000 (92%)]\tLoss: -29.472185\n",
      "Train Epoch: 20 [56320/60000 (94%)]\tLoss: -29.511806\n",
      "Train Epoch: 20 [57600/60000 (96%)]\tLoss: -29.711447\n",
      "Train Epoch: 20 [58880/60000 (98%)]\tLoss: -29.971991\n",
      "====> Epoch: 20 Average loss: -29.5794\n",
      "====> Test set loss: -29.9974\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: -29.798023\n",
      "Train Epoch: 21 [1280/60000 (2%)]\tLoss: -29.854008\n",
      "Train Epoch: 21 [2560/60000 (4%)]\tLoss: -29.822433\n",
      "Train Epoch: 21 [3840/60000 (6%)]\tLoss: -30.119608\n",
      "Train Epoch: 21 [5120/60000 (9%)]\tLoss: -29.490255\n",
      "Train Epoch: 21 [6400/60000 (11%)]\tLoss: -29.235994\n",
      "Train Epoch: 21 [7680/60000 (13%)]\tLoss: -29.797213\n",
      "Train Epoch: 21 [8960/60000 (15%)]\tLoss: -29.850309\n",
      "Train Epoch: 21 [10240/60000 (17%)]\tLoss: -29.478899\n",
      "Train Epoch: 21 [11520/60000 (19%)]\tLoss: -29.568983\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: -29.478188\n",
      "Train Epoch: 21 [14080/60000 (23%)]\tLoss: -29.487402\n",
      "Train Epoch: 21 [15360/60000 (26%)]\tLoss: -29.575432\n",
      "Train Epoch: 21 [16640/60000 (28%)]\tLoss: -29.778578\n",
      "Train Epoch: 21 [17920/60000 (30%)]\tLoss: -29.218201\n",
      "Train Epoch: 21 [19200/60000 (32%)]\tLoss: -29.721720\n",
      "Train Epoch: 21 [20480/60000 (34%)]\tLoss: -29.419838\n",
      "Train Epoch: 21 [21760/60000 (36%)]\tLoss: -29.521215\n",
      "Train Epoch: 21 [23040/60000 (38%)]\tLoss: -29.260506\n",
      "Train Epoch: 21 [24320/60000 (41%)]\tLoss: -29.561018\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: -29.423723\n",
      "Train Epoch: 21 [26880/60000 (45%)]\tLoss: -29.619648\n",
      "Train Epoch: 21 [28160/60000 (47%)]\tLoss: -29.635382\n",
      "Train Epoch: 21 [29440/60000 (49%)]\tLoss: -29.192471\n",
      "Train Epoch: 21 [30720/60000 (51%)]\tLoss: -29.694727\n",
      "Train Epoch: 21 [32000/60000 (53%)]\tLoss: -29.556709\n",
      "Train Epoch: 21 [33280/60000 (55%)]\tLoss: -29.501741\n",
      "Train Epoch: 21 [34560/60000 (58%)]\tLoss: -29.820288\n",
      "Train Epoch: 21 [35840/60000 (60%)]\tLoss: -29.627012\n",
      "Train Epoch: 21 [37120/60000 (62%)]\tLoss: -29.928455\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: -29.558117\n",
      "Train Epoch: 21 [39680/60000 (66%)]\tLoss: -29.662159\n",
      "Train Epoch: 21 [40960/60000 (68%)]\tLoss: -29.911892\n",
      "Train Epoch: 21 [42240/60000 (70%)]\tLoss: -29.773350\n",
      "Train Epoch: 21 [43520/60000 (72%)]\tLoss: -29.671240\n",
      "Train Epoch: 21 [44800/60000 (75%)]\tLoss: -29.685530\n",
      "Train Epoch: 21 [46080/60000 (77%)]\tLoss: -29.723913\n",
      "Train Epoch: 21 [47360/60000 (79%)]\tLoss: -29.427729\n",
      "Train Epoch: 21 [48640/60000 (81%)]\tLoss: -29.199074\n",
      "Train Epoch: 21 [49920/60000 (83%)]\tLoss: -29.643564\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: -29.676363\n",
      "Train Epoch: 21 [52480/60000 (87%)]\tLoss: -29.890421\n",
      "Train Epoch: 21 [53760/60000 (90%)]\tLoss: -29.612226\n",
      "Train Epoch: 21 [55040/60000 (92%)]\tLoss: -29.751867\n",
      "Train Epoch: 21 [56320/60000 (94%)]\tLoss: -29.726412\n",
      "Train Epoch: 21 [57600/60000 (96%)]\tLoss: -29.176905\n",
      "Train Epoch: 21 [58880/60000 (98%)]\tLoss: -29.867504\n",
      "====> Epoch: 21 Average loss: -29.6236\n",
      "====> Test set loss: -29.9798\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: -29.797806\n",
      "Train Epoch: 22 [1280/60000 (2%)]\tLoss: -29.365761\n",
      "Train Epoch: 22 [2560/60000 (4%)]\tLoss: -29.576107\n",
      "Train Epoch: 22 [3840/60000 (6%)]\tLoss: -29.670523\n",
      "Train Epoch: 22 [5120/60000 (9%)]\tLoss: -29.979321\n",
      "Train Epoch: 22 [6400/60000 (11%)]\tLoss: -29.476200\n",
      "Train Epoch: 22 [7680/60000 (13%)]\tLoss: -29.624857\n",
      "Train Epoch: 22 [8960/60000 (15%)]\tLoss: -29.488060\n",
      "Train Epoch: 22 [10240/60000 (17%)]\tLoss: -29.860535\n",
      "Train Epoch: 22 [11520/60000 (19%)]\tLoss: -29.532316\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: -29.719818\n",
      "Train Epoch: 22 [14080/60000 (23%)]\tLoss: -29.661522\n",
      "Train Epoch: 22 [15360/60000 (26%)]\tLoss: -29.326731\n",
      "Train Epoch: 22 [16640/60000 (28%)]\tLoss: -29.783125\n",
      "Train Epoch: 22 [17920/60000 (30%)]\tLoss: -29.593992\n",
      "Train Epoch: 22 [19200/60000 (32%)]\tLoss: -29.938360\n",
      "Train Epoch: 22 [20480/60000 (34%)]\tLoss: -29.794748\n",
      "Train Epoch: 22 [21760/60000 (36%)]\tLoss: -28.973677\n",
      "Train Epoch: 22 [23040/60000 (38%)]\tLoss: -29.536314\n",
      "Train Epoch: 22 [24320/60000 (41%)]\tLoss: -29.364023\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: -29.609272\n",
      "Train Epoch: 22 [26880/60000 (45%)]\tLoss: -29.367294\n",
      "Train Epoch: 22 [28160/60000 (47%)]\tLoss: -29.414513\n",
      "Train Epoch: 22 [29440/60000 (49%)]\tLoss: -30.043367\n",
      "Train Epoch: 22 [30720/60000 (51%)]\tLoss: -29.938984\n",
      "Train Epoch: 22 [32000/60000 (53%)]\tLoss: -29.796616\n",
      "Train Epoch: 22 [33280/60000 (55%)]\tLoss: -29.816151\n",
      "Train Epoch: 22 [34560/60000 (58%)]\tLoss: -29.412609\n",
      "Train Epoch: 22 [35840/60000 (60%)]\tLoss: -29.074917\n",
      "Train Epoch: 22 [37120/60000 (62%)]\tLoss: -29.371529\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: -29.608921\n",
      "Train Epoch: 22 [39680/60000 (66%)]\tLoss: -30.153471\n",
      "Train Epoch: 22 [40960/60000 (68%)]\tLoss: -29.709019\n",
      "Train Epoch: 22 [42240/60000 (70%)]\tLoss: -29.905872\n",
      "Train Epoch: 22 [43520/60000 (72%)]\tLoss: -29.793478\n",
      "Train Epoch: 22 [44800/60000 (75%)]\tLoss: -29.837078\n",
      "Train Epoch: 22 [46080/60000 (77%)]\tLoss: -29.119423\n",
      "Train Epoch: 22 [47360/60000 (79%)]\tLoss: -29.935644\n",
      "Train Epoch: 22 [48640/60000 (81%)]\tLoss: -29.401009\n",
      "Train Epoch: 22 [49920/60000 (83%)]\tLoss: -29.860813\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: -29.575462\n",
      "Train Epoch: 22 [52480/60000 (87%)]\tLoss: -29.617342\n",
      "Train Epoch: 22 [53760/60000 (90%)]\tLoss: -29.483723\n",
      "Train Epoch: 22 [55040/60000 (92%)]\tLoss: -29.259769\n",
      "Train Epoch: 22 [56320/60000 (94%)]\tLoss: -29.425575\n",
      "Train Epoch: 22 [57600/60000 (96%)]\tLoss: -29.854113\n",
      "Train Epoch: 22 [58880/60000 (98%)]\tLoss: -29.477100\n",
      "====> Epoch: 22 Average loss: -29.6187\n",
      "====> Test set loss: -29.9726\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: -29.981844\n",
      "Train Epoch: 23 [1280/60000 (2%)]\tLoss: -29.710337\n",
      "Train Epoch: 23 [2560/60000 (4%)]\tLoss: -29.700386\n",
      "Train Epoch: 23 [3840/60000 (6%)]\tLoss: -29.575203\n",
      "Train Epoch: 23 [5120/60000 (9%)]\tLoss: -29.949522\n",
      "Train Epoch: 23 [6400/60000 (11%)]\tLoss: -29.587881\n",
      "Train Epoch: 23 [7680/60000 (13%)]\tLoss: -30.032642\n",
      "Train Epoch: 23 [8960/60000 (15%)]\tLoss: -29.842566\n",
      "Train Epoch: 23 [10240/60000 (17%)]\tLoss: -29.780725\n",
      "Train Epoch: 23 [11520/60000 (19%)]\tLoss: -29.510656\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: -29.210077\n",
      "Train Epoch: 23 [14080/60000 (23%)]\tLoss: -29.804745\n",
      "Train Epoch: 23 [15360/60000 (26%)]\tLoss: -29.293182\n",
      "Train Epoch: 23 [16640/60000 (28%)]\tLoss: -29.717665\n",
      "Train Epoch: 23 [17920/60000 (30%)]\tLoss: -29.348841\n",
      "Train Epoch: 23 [19200/60000 (32%)]\tLoss: -29.888861\n",
      "Train Epoch: 23 [20480/60000 (34%)]\tLoss: -29.691256\n",
      "Train Epoch: 23 [21760/60000 (36%)]\tLoss: -29.924765\n",
      "Train Epoch: 23 [23040/60000 (38%)]\tLoss: -29.557016\n",
      "Train Epoch: 23 [24320/60000 (41%)]\tLoss: -29.789707\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: -29.464661\n",
      "Train Epoch: 23 [26880/60000 (45%)]\tLoss: -29.620802\n",
      "Train Epoch: 23 [28160/60000 (47%)]\tLoss: -29.852762\n",
      "Train Epoch: 23 [29440/60000 (49%)]\tLoss: -30.079447\n",
      "Train Epoch: 23 [30720/60000 (51%)]\tLoss: -29.562355\n",
      "Train Epoch: 23 [32000/60000 (53%)]\tLoss: -29.588938\n",
      "Train Epoch: 23 [33280/60000 (55%)]\tLoss: -29.813414\n",
      "Train Epoch: 23 [34560/60000 (58%)]\tLoss: -29.646509\n",
      "Train Epoch: 23 [35840/60000 (60%)]\tLoss: -29.598345\n",
      "Train Epoch: 23 [37120/60000 (62%)]\tLoss: -29.259068\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: -29.955856\n",
      "Train Epoch: 23 [39680/60000 (66%)]\tLoss: -29.890591\n",
      "Train Epoch: 23 [40960/60000 (68%)]\tLoss: -29.429310\n",
      "Train Epoch: 23 [42240/60000 (70%)]\tLoss: -29.427637\n",
      "Train Epoch: 23 [43520/60000 (72%)]\tLoss: -29.787226\n",
      "Train Epoch: 23 [44800/60000 (75%)]\tLoss: -29.831671\n",
      "Train Epoch: 23 [46080/60000 (77%)]\tLoss: -29.540382\n",
      "Train Epoch: 23 [47360/60000 (79%)]\tLoss: -29.666639\n",
      "Train Epoch: 23 [48640/60000 (81%)]\tLoss: -29.332132\n",
      "Train Epoch: 23 [49920/60000 (83%)]\tLoss: -30.180687\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: -29.438543\n",
      "Train Epoch: 23 [52480/60000 (87%)]\tLoss: -29.592821\n",
      "Train Epoch: 23 [53760/60000 (90%)]\tLoss: -29.880562\n",
      "Train Epoch: 23 [55040/60000 (92%)]\tLoss: -29.651249\n",
      "Train Epoch: 23 [56320/60000 (94%)]\tLoss: -29.807467\n",
      "Train Epoch: 23 [57600/60000 (96%)]\tLoss: -29.765820\n",
      "Train Epoch: 23 [58880/60000 (98%)]\tLoss: -29.919683\n",
      "====> Epoch: 23 Average loss: -29.7273\n",
      "====> Test set loss: -30.0506\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: -29.632824\n",
      "Train Epoch: 24 [1280/60000 (2%)]\tLoss: -29.591778\n",
      "Train Epoch: 24 [2560/60000 (4%)]\tLoss: -29.633770\n",
      "Train Epoch: 24 [3840/60000 (6%)]\tLoss: -29.442545\n",
      "Train Epoch: 24 [5120/60000 (9%)]\tLoss: -29.432358\n",
      "Train Epoch: 24 [6400/60000 (11%)]\tLoss: -29.769375\n",
      "Train Epoch: 24 [7680/60000 (13%)]\tLoss: -29.728868\n",
      "Train Epoch: 24 [8960/60000 (15%)]\tLoss: -29.612484\n",
      "Train Epoch: 24 [10240/60000 (17%)]\tLoss: -29.868593\n",
      "Train Epoch: 24 [11520/60000 (19%)]\tLoss: -29.961113\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: -29.652458\n",
      "Train Epoch: 24 [14080/60000 (23%)]\tLoss: -29.905918\n",
      "Train Epoch: 24 [15360/60000 (26%)]\tLoss: -29.777481\n",
      "Train Epoch: 24 [16640/60000 (28%)]\tLoss: -29.895267\n",
      "Train Epoch: 24 [17920/60000 (30%)]\tLoss: -30.118511\n",
      "Train Epoch: 24 [19200/60000 (32%)]\tLoss: -29.936022\n",
      "Train Epoch: 24 [20480/60000 (34%)]\tLoss: -29.806774\n",
      "Train Epoch: 24 [21760/60000 (36%)]\tLoss: -29.179499\n",
      "Train Epoch: 24 [23040/60000 (38%)]\tLoss: -28.998356\n",
      "Train Epoch: 24 [24320/60000 (41%)]\tLoss: -29.370388\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: -29.624088\n",
      "Train Epoch: 24 [26880/60000 (45%)]\tLoss: -29.790323\n",
      "Train Epoch: 24 [28160/60000 (47%)]\tLoss: -29.917410\n",
      "Train Epoch: 24 [29440/60000 (49%)]\tLoss: -29.248989\n",
      "Train Epoch: 24 [30720/60000 (51%)]\tLoss: -29.613129\n",
      "Train Epoch: 24 [32000/60000 (53%)]\tLoss: -29.558283\n",
      "Train Epoch: 24 [33280/60000 (55%)]\tLoss: -29.779657\n",
      "Train Epoch: 24 [34560/60000 (58%)]\tLoss: -29.358210\n",
      "Train Epoch: 24 [35840/60000 (60%)]\tLoss: -29.760796\n",
      "Train Epoch: 24 [37120/60000 (62%)]\tLoss: -29.396212\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: -29.611662\n",
      "Train Epoch: 24 [39680/60000 (66%)]\tLoss: -29.731123\n",
      "Train Epoch: 24 [40960/60000 (68%)]\tLoss: -29.552679\n",
      "Train Epoch: 24 [42240/60000 (70%)]\tLoss: -29.765648\n",
      "Train Epoch: 24 [43520/60000 (72%)]\tLoss: -29.522518\n",
      "Train Epoch: 24 [44800/60000 (75%)]\tLoss: -29.245363\n",
      "Train Epoch: 24 [46080/60000 (77%)]\tLoss: -29.598139\n",
      "Train Epoch: 24 [47360/60000 (79%)]\tLoss: -29.580587\n",
      "Train Epoch: 24 [48640/60000 (81%)]\tLoss: -29.144562\n",
      "Train Epoch: 24 [49920/60000 (83%)]\tLoss: -29.236830\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: -29.986937\n",
      "Train Epoch: 24 [52480/60000 (87%)]\tLoss: -29.656731\n",
      "Train Epoch: 24 [53760/60000 (90%)]\tLoss: -29.501888\n",
      "Train Epoch: 24 [55040/60000 (92%)]\tLoss: -29.972300\n",
      "Train Epoch: 24 [56320/60000 (94%)]\tLoss: -29.674938\n",
      "Train Epoch: 24 [57600/60000 (96%)]\tLoss: -29.777258\n",
      "Train Epoch: 24 [58880/60000 (98%)]\tLoss: -29.833675\n",
      "====> Epoch: 24 Average loss: -29.6665\n",
      "====> Test set loss: -30.0234\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: -29.297714\n",
      "Train Epoch: 25 [1280/60000 (2%)]\tLoss: -29.829788\n",
      "Train Epoch: 25 [2560/60000 (4%)]\tLoss: -29.889412\n",
      "Train Epoch: 25 [3840/60000 (6%)]\tLoss: -29.859358\n",
      "Train Epoch: 25 [5120/60000 (9%)]\tLoss: -29.868580\n",
      "Train Epoch: 25 [6400/60000 (11%)]\tLoss: -29.641111\n",
      "Train Epoch: 25 [7680/60000 (13%)]\tLoss: -29.862558\n",
      "Train Epoch: 25 [8960/60000 (15%)]\tLoss: -29.805790\n",
      "Train Epoch: 25 [10240/60000 (17%)]\tLoss: -29.714890\n",
      "Train Epoch: 25 [11520/60000 (19%)]\tLoss: -29.766735\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: -29.790506\n",
      "Train Epoch: 25 [14080/60000 (23%)]\tLoss: -29.873362\n",
      "Train Epoch: 25 [15360/60000 (26%)]\tLoss: -30.259146\n",
      "Train Epoch: 25 [16640/60000 (28%)]\tLoss: -29.479380\n",
      "Train Epoch: 25 [17920/60000 (30%)]\tLoss: -29.756750\n",
      "Train Epoch: 25 [19200/60000 (32%)]\tLoss: -30.140543\n",
      "Train Epoch: 25 [20480/60000 (34%)]\tLoss: -29.900948\n",
      "Train Epoch: 25 [21760/60000 (36%)]\tLoss: -29.987411\n",
      "Train Epoch: 25 [23040/60000 (38%)]\tLoss: -29.892693\n",
      "Train Epoch: 25 [24320/60000 (41%)]\tLoss: -29.892342\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: -29.592859\n",
      "Train Epoch: 25 [26880/60000 (45%)]\tLoss: -29.591316\n",
      "Train Epoch: 25 [28160/60000 (47%)]\tLoss: -29.923458\n",
      "Train Epoch: 25 [29440/60000 (49%)]\tLoss: -29.735826\n",
      "Train Epoch: 25 [30720/60000 (51%)]\tLoss: -29.327805\n",
      "Train Epoch: 25 [32000/60000 (53%)]\tLoss: -30.104338\n",
      "Train Epoch: 25 [33280/60000 (55%)]\tLoss: -29.885706\n",
      "Train Epoch: 25 [34560/60000 (58%)]\tLoss: -29.781593\n",
      "Train Epoch: 25 [35840/60000 (60%)]\tLoss: -29.551851\n",
      "Train Epoch: 25 [37120/60000 (62%)]\tLoss: -29.850052\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: -29.724525\n",
      "Train Epoch: 25 [39680/60000 (66%)]\tLoss: -29.944962\n",
      "Train Epoch: 25 [40960/60000 (68%)]\tLoss: -30.260244\n",
      "Train Epoch: 25 [42240/60000 (70%)]\tLoss: -29.814287\n",
      "Train Epoch: 25 [43520/60000 (72%)]\tLoss: -30.094236\n",
      "Train Epoch: 25 [44800/60000 (75%)]\tLoss: -30.252604\n",
      "Train Epoch: 25 [46080/60000 (77%)]\tLoss: -29.769455\n",
      "Train Epoch: 25 [47360/60000 (79%)]\tLoss: -29.989265\n",
      "Train Epoch: 25 [48640/60000 (81%)]\tLoss: -30.119093\n",
      "Train Epoch: 25 [49920/60000 (83%)]\tLoss: -30.094603\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: -30.069439\n",
      "Train Epoch: 25 [52480/60000 (87%)]\tLoss: -29.920033\n",
      "Train Epoch: 25 [53760/60000 (90%)]\tLoss: -29.922289\n",
      "Train Epoch: 25 [55040/60000 (92%)]\tLoss: -29.745380\n",
      "Train Epoch: 25 [56320/60000 (94%)]\tLoss: -29.954021\n",
      "Train Epoch: 25 [57600/60000 (96%)]\tLoss: -29.656631\n",
      "Train Epoch: 25 [58880/60000 (98%)]\tLoss: -29.457733\n",
      "====> Epoch: 25 Average loss: -29.8752\n",
      "====> Test set loss: -30.2248\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: -29.953930\n",
      "Train Epoch: 26 [1280/60000 (2%)]\tLoss: -29.628592\n",
      "Train Epoch: 26 [2560/60000 (4%)]\tLoss: -30.252136\n",
      "Train Epoch: 26 [3840/60000 (6%)]\tLoss: -29.982676\n",
      "Train Epoch: 26 [5120/60000 (9%)]\tLoss: -30.091116\n",
      "Train Epoch: 26 [6400/60000 (11%)]\tLoss: -29.760822\n",
      "Train Epoch: 26 [7680/60000 (13%)]\tLoss: -29.628803\n",
      "Train Epoch: 26 [8960/60000 (15%)]\tLoss: -30.339058\n",
      "Train Epoch: 26 [10240/60000 (17%)]\tLoss: -30.405020\n",
      "Train Epoch: 26 [11520/60000 (19%)]\tLoss: -29.942675\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: -29.913504\n",
      "Train Epoch: 26 [14080/60000 (23%)]\tLoss: -29.917213\n",
      "Train Epoch: 26 [15360/60000 (26%)]\tLoss: -30.489279\n",
      "Train Epoch: 26 [16640/60000 (28%)]\tLoss: -29.871956\n",
      "Train Epoch: 26 [17920/60000 (30%)]\tLoss: -29.776014\n",
      "Train Epoch: 26 [19200/60000 (32%)]\tLoss: -29.362074\n",
      "Train Epoch: 26 [20480/60000 (34%)]\tLoss: -30.143991\n",
      "Train Epoch: 26 [21760/60000 (36%)]\tLoss: -29.471821\n",
      "Train Epoch: 26 [23040/60000 (38%)]\tLoss: -29.578672\n",
      "Train Epoch: 26 [24320/60000 (41%)]\tLoss: -29.826817\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: -29.735600\n",
      "Train Epoch: 26 [26880/60000 (45%)]\tLoss: -29.738655\n",
      "Train Epoch: 26 [28160/60000 (47%)]\tLoss: -29.461721\n",
      "Train Epoch: 26 [29440/60000 (49%)]\tLoss: -29.692881\n",
      "Train Epoch: 26 [30720/60000 (51%)]\tLoss: -29.672913\n",
      "Train Epoch: 26 [32000/60000 (53%)]\tLoss: -29.966915\n",
      "Train Epoch: 26 [33280/60000 (55%)]\tLoss: -29.968319\n",
      "Train Epoch: 26 [34560/60000 (58%)]\tLoss: -29.524439\n",
      "Train Epoch: 26 [35840/60000 (60%)]\tLoss: -30.061104\n",
      "Train Epoch: 26 [37120/60000 (62%)]\tLoss: -30.073992\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: -30.181742\n",
      "Train Epoch: 26 [39680/60000 (66%)]\tLoss: -30.186529\n",
      "Train Epoch: 26 [40960/60000 (68%)]\tLoss: -30.425098\n",
      "Train Epoch: 26 [42240/60000 (70%)]\tLoss: -30.063021\n",
      "Train Epoch: 26 [43520/60000 (72%)]\tLoss: -29.933929\n",
      "Train Epoch: 26 [44800/60000 (75%)]\tLoss: -29.524931\n",
      "Train Epoch: 26 [46080/60000 (77%)]\tLoss: -29.756781\n",
      "Train Epoch: 26 [47360/60000 (79%)]\tLoss: -29.968128\n",
      "Train Epoch: 26 [48640/60000 (81%)]\tLoss: -30.404831\n",
      "Train Epoch: 26 [49920/60000 (83%)]\tLoss: -29.857971\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: -30.018740\n",
      "Train Epoch: 26 [52480/60000 (87%)]\tLoss: -29.772594\n",
      "Train Epoch: 26 [53760/60000 (90%)]\tLoss: -29.941206\n",
      "Train Epoch: 26 [55040/60000 (92%)]\tLoss: -29.908613\n",
      "Train Epoch: 26 [56320/60000 (94%)]\tLoss: -29.961370\n",
      "Train Epoch: 26 [57600/60000 (96%)]\tLoss: -30.027102\n",
      "Train Epoch: 26 [58880/60000 (98%)]\tLoss: -29.988264\n",
      "====> Epoch: 26 Average loss: -29.9130\n",
      "====> Test set loss: -30.2864\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: -30.002851\n",
      "Train Epoch: 27 [1280/60000 (2%)]\tLoss: -30.036470\n",
      "Train Epoch: 27 [2560/60000 (4%)]\tLoss: -30.153170\n",
      "Train Epoch: 27 [3840/60000 (6%)]\tLoss: -29.592442\n",
      "Train Epoch: 27 [5120/60000 (9%)]\tLoss: -30.319744\n",
      "Train Epoch: 27 [6400/60000 (11%)]\tLoss: -29.890606\n",
      "Train Epoch: 27 [7680/60000 (13%)]\tLoss: -30.213434\n",
      "Train Epoch: 27 [8960/60000 (15%)]\tLoss: -30.213699\n",
      "Train Epoch: 27 [10240/60000 (17%)]\tLoss: -30.166388\n",
      "Train Epoch: 27 [11520/60000 (19%)]\tLoss: -30.308844\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: -30.253691\n",
      "Train Epoch: 27 [14080/60000 (23%)]\tLoss: -29.941681\n",
      "Train Epoch: 27 [15360/60000 (26%)]\tLoss: -29.738863\n",
      "Train Epoch: 27 [16640/60000 (28%)]\tLoss: -29.770361\n",
      "Train Epoch: 27 [17920/60000 (30%)]\tLoss: -29.889320\n",
      "Train Epoch: 27 [19200/60000 (32%)]\tLoss: -29.465397\n",
      "Train Epoch: 27 [20480/60000 (34%)]\tLoss: -29.614973\n",
      "Train Epoch: 27 [21760/60000 (36%)]\tLoss: -29.635653\n",
      "Train Epoch: 27 [23040/60000 (38%)]\tLoss: -29.821859\n",
      "Train Epoch: 27 [24320/60000 (41%)]\tLoss: -29.609840\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: -29.931200\n",
      "Train Epoch: 27 [26880/60000 (45%)]\tLoss: -29.847422\n",
      "Train Epoch: 27 [28160/60000 (47%)]\tLoss: -30.239079\n",
      "Train Epoch: 27 [29440/60000 (49%)]\tLoss: -29.901888\n",
      "Train Epoch: 27 [30720/60000 (51%)]\tLoss: -29.970934\n",
      "Train Epoch: 27 [32000/60000 (53%)]\tLoss: -29.541567\n",
      "Train Epoch: 27 [33280/60000 (55%)]\tLoss: -29.712835\n",
      "Train Epoch: 27 [34560/60000 (58%)]\tLoss: -29.815529\n",
      "Train Epoch: 27 [35840/60000 (60%)]\tLoss: -29.826147\n",
      "Train Epoch: 27 [37120/60000 (62%)]\tLoss: -30.221973\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: -29.652702\n",
      "Train Epoch: 27 [39680/60000 (66%)]\tLoss: -30.078718\n",
      "Train Epoch: 27 [40960/60000 (68%)]\tLoss: -30.084499\n",
      "Train Epoch: 27 [42240/60000 (70%)]\tLoss: -30.260014\n",
      "Train Epoch: 27 [43520/60000 (72%)]\tLoss: -29.621584\n",
      "Train Epoch: 27 [44800/60000 (75%)]\tLoss: -29.752439\n",
      "Train Epoch: 27 [46080/60000 (77%)]\tLoss: -29.678112\n",
      "Train Epoch: 27 [47360/60000 (79%)]\tLoss: -29.983431\n",
      "Train Epoch: 27 [48640/60000 (81%)]\tLoss: -30.085257\n",
      "Train Epoch: 27 [49920/60000 (83%)]\tLoss: -29.587265\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: -29.804361\n",
      "Train Epoch: 27 [52480/60000 (87%)]\tLoss: -30.394814\n",
      "Train Epoch: 27 [53760/60000 (90%)]\tLoss: -29.837524\n",
      "Train Epoch: 27 [55040/60000 (92%)]\tLoss: -29.955379\n",
      "Train Epoch: 27 [56320/60000 (94%)]\tLoss: -30.138327\n",
      "Train Epoch: 27 [57600/60000 (96%)]\tLoss: -29.602415\n",
      "Train Epoch: 27 [58880/60000 (98%)]\tLoss: -29.880541\n",
      "====> Epoch: 27 Average loss: -29.9440\n",
      "====> Test set loss: -30.3015\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: -30.124863\n",
      "Train Epoch: 28 [1280/60000 (2%)]\tLoss: -29.819008\n",
      "Train Epoch: 28 [2560/60000 (4%)]\tLoss: -29.708012\n",
      "Train Epoch: 28 [3840/60000 (6%)]\tLoss: -30.259335\n",
      "Train Epoch: 28 [5120/60000 (9%)]\tLoss: -30.075563\n",
      "Train Epoch: 28 [6400/60000 (11%)]\tLoss: -29.781902\n",
      "Train Epoch: 28 [7680/60000 (13%)]\tLoss: -29.812513\n",
      "Train Epoch: 28 [8960/60000 (15%)]\tLoss: -29.701408\n",
      "Train Epoch: 28 [10240/60000 (17%)]\tLoss: -29.843075\n",
      "Train Epoch: 28 [11520/60000 (19%)]\tLoss: -29.801382\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: -30.462364\n",
      "Train Epoch: 28 [14080/60000 (23%)]\tLoss: -29.387445\n",
      "Train Epoch: 28 [15360/60000 (26%)]\tLoss: -30.137529\n",
      "Train Epoch: 28 [16640/60000 (28%)]\tLoss: -29.852924\n",
      "Train Epoch: 28 [17920/60000 (30%)]\tLoss: -30.123852\n",
      "Train Epoch: 28 [19200/60000 (32%)]\tLoss: -29.965723\n",
      "Train Epoch: 28 [20480/60000 (34%)]\tLoss: -29.561329\n",
      "Train Epoch: 28 [21760/60000 (36%)]\tLoss: -29.750423\n",
      "Train Epoch: 28 [23040/60000 (38%)]\tLoss: -29.421362\n",
      "Train Epoch: 28 [24320/60000 (41%)]\tLoss: -29.778246\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: -30.206961\n",
      "Train Epoch: 28 [26880/60000 (45%)]\tLoss: -29.963873\n",
      "Train Epoch: 28 [28160/60000 (47%)]\tLoss: -29.542074\n",
      "Train Epoch: 28 [29440/60000 (49%)]\tLoss: -30.002710\n",
      "Train Epoch: 28 [30720/60000 (51%)]\tLoss: -29.994980\n",
      "Train Epoch: 28 [32000/60000 (53%)]\tLoss: -29.616119\n",
      "Train Epoch: 28 [33280/60000 (55%)]\tLoss: -30.189274\n",
      "Train Epoch: 28 [34560/60000 (58%)]\tLoss: -30.011925\n",
      "Train Epoch: 28 [35840/60000 (60%)]\tLoss: -29.528833\n",
      "Train Epoch: 28 [37120/60000 (62%)]\tLoss: -29.944269\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: -30.060165\n",
      "Train Epoch: 28 [39680/60000 (66%)]\tLoss: -30.424820\n",
      "Train Epoch: 28 [40960/60000 (68%)]\tLoss: -30.057228\n",
      "Train Epoch: 28 [42240/60000 (70%)]\tLoss: -30.024273\n",
      "Train Epoch: 28 [43520/60000 (72%)]\tLoss: -29.582123\n",
      "Train Epoch: 28 [44800/60000 (75%)]\tLoss: -30.121712\n",
      "Train Epoch: 28 [46080/60000 (77%)]\tLoss: -30.077730\n",
      "Train Epoch: 28 [47360/60000 (79%)]\tLoss: -30.176390\n",
      "Train Epoch: 28 [48640/60000 (81%)]\tLoss: -29.602594\n",
      "Train Epoch: 28 [49920/60000 (83%)]\tLoss: -29.837929\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: -29.844334\n",
      "Train Epoch: 28 [52480/60000 (87%)]\tLoss: -30.011856\n",
      "Train Epoch: 28 [53760/60000 (90%)]\tLoss: -30.018589\n",
      "Train Epoch: 28 [55040/60000 (92%)]\tLoss: -29.802660\n",
      "Train Epoch: 28 [56320/60000 (94%)]\tLoss: -29.941164\n",
      "Train Epoch: 28 [57600/60000 (96%)]\tLoss: -29.742020\n",
      "Train Epoch: 28 [58880/60000 (98%)]\tLoss: -30.044046\n",
      "====> Epoch: 28 Average loss: -29.9443\n",
      "====> Test set loss: -30.2432\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: -29.771250\n",
      "Train Epoch: 29 [1280/60000 (2%)]\tLoss: -29.959934\n",
      "Train Epoch: 29 [2560/60000 (4%)]\tLoss: -29.835436\n",
      "Train Epoch: 29 [3840/60000 (6%)]\tLoss: -29.725157\n",
      "Train Epoch: 29 [5120/60000 (9%)]\tLoss: -30.224085\n",
      "Train Epoch: 29 [6400/60000 (11%)]\tLoss: -29.778114\n",
      "Train Epoch: 29 [7680/60000 (13%)]\tLoss: -30.451895\n",
      "Train Epoch: 29 [8960/60000 (15%)]\tLoss: -29.620888\n",
      "Train Epoch: 29 [10240/60000 (17%)]\tLoss: -29.880150\n",
      "Train Epoch: 29 [11520/60000 (19%)]\tLoss: -29.627928\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: -29.653709\n",
      "Train Epoch: 29 [14080/60000 (23%)]\tLoss: -29.547104\n",
      "Train Epoch: 29 [15360/60000 (26%)]\tLoss: -29.724304\n",
      "Train Epoch: 29 [16640/60000 (28%)]\tLoss: -30.158947\n",
      "Train Epoch: 29 [17920/60000 (30%)]\tLoss: -30.066893\n",
      "Train Epoch: 29 [19200/60000 (32%)]\tLoss: -30.071411\n",
      "Train Epoch: 29 [20480/60000 (34%)]\tLoss: -29.822847\n",
      "Train Epoch: 29 [21760/60000 (36%)]\tLoss: -29.851669\n",
      "Train Epoch: 29 [23040/60000 (38%)]\tLoss: -30.201403\n",
      "Train Epoch: 29 [24320/60000 (41%)]\tLoss: -29.972643\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: -30.194864\n",
      "Train Epoch: 29 [26880/60000 (45%)]\tLoss: -30.021320\n",
      "Train Epoch: 29 [28160/60000 (47%)]\tLoss: -30.295107\n",
      "Train Epoch: 29 [29440/60000 (49%)]\tLoss: -30.017784\n",
      "Train Epoch: 29 [30720/60000 (51%)]\tLoss: -29.818712\n",
      "Train Epoch: 29 [32000/60000 (53%)]\tLoss: -29.852041\n",
      "Train Epoch: 29 [33280/60000 (55%)]\tLoss: -30.072943\n",
      "Train Epoch: 29 [34560/60000 (58%)]\tLoss: -29.976068\n",
      "Train Epoch: 29 [35840/60000 (60%)]\tLoss: -29.753492\n",
      "Train Epoch: 29 [37120/60000 (62%)]\tLoss: -29.783392\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: -29.994438\n",
      "Train Epoch: 29 [39680/60000 (66%)]\tLoss: -29.652594\n",
      "Train Epoch: 29 [40960/60000 (68%)]\tLoss: -29.952557\n",
      "Train Epoch: 29 [42240/60000 (70%)]\tLoss: -30.273241\n",
      "Train Epoch: 29 [43520/60000 (72%)]\tLoss: -29.856966\n",
      "Train Epoch: 29 [44800/60000 (75%)]\tLoss: -29.932093\n",
      "Train Epoch: 29 [46080/60000 (77%)]\tLoss: -29.890348\n",
      "Train Epoch: 29 [47360/60000 (79%)]\tLoss: -29.991468\n",
      "Train Epoch: 29 [48640/60000 (81%)]\tLoss: -29.900595\n",
      "Train Epoch: 29 [49920/60000 (83%)]\tLoss: -29.784031\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: -30.177881\n",
      "Train Epoch: 29 [52480/60000 (87%)]\tLoss: -30.075554\n",
      "Train Epoch: 29 [53760/60000 (90%)]\tLoss: -29.833473\n",
      "Train Epoch: 29 [55040/60000 (92%)]\tLoss: -30.228609\n",
      "Train Epoch: 29 [56320/60000 (94%)]\tLoss: -29.660570\n",
      "Train Epoch: 29 [57600/60000 (96%)]\tLoss: -29.941351\n",
      "Train Epoch: 29 [58880/60000 (98%)]\tLoss: -29.715420\n",
      "====> Epoch: 29 Average loss: -29.9538\n",
      "====> Test set loss: -30.2458\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: -30.170006\n",
      "Train Epoch: 30 [1280/60000 (2%)]\tLoss: -30.167627\n",
      "Train Epoch: 30 [2560/60000 (4%)]\tLoss: -29.752438\n",
      "Train Epoch: 30 [3840/60000 (6%)]\tLoss: -29.615416\n",
      "Train Epoch: 30 [5120/60000 (9%)]\tLoss: -29.716352\n",
      "Train Epoch: 30 [6400/60000 (11%)]\tLoss: -30.045938\n",
      "Train Epoch: 30 [7680/60000 (13%)]\tLoss: -29.940100\n",
      "Train Epoch: 30 [8960/60000 (15%)]\tLoss: -29.857109\n",
      "Train Epoch: 30 [10240/60000 (17%)]\tLoss: -29.771774\n",
      "Train Epoch: 30 [11520/60000 (19%)]\tLoss: -29.826729\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: -30.198921\n",
      "Train Epoch: 30 [14080/60000 (23%)]\tLoss: -30.213854\n",
      "Train Epoch: 30 [15360/60000 (26%)]\tLoss: -30.155012\n",
      "Train Epoch: 30 [16640/60000 (28%)]\tLoss: -29.909430\n",
      "Train Epoch: 30 [17920/60000 (30%)]\tLoss: -29.757988\n",
      "Train Epoch: 30 [19200/60000 (32%)]\tLoss: -29.636757\n",
      "Train Epoch: 30 [20480/60000 (34%)]\tLoss: -30.124104\n",
      "Train Epoch: 30 [21760/60000 (36%)]\tLoss: -29.635286\n",
      "Train Epoch: 30 [23040/60000 (38%)]\tLoss: -30.055786\n",
      "Train Epoch: 30 [24320/60000 (41%)]\tLoss: -29.836937\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: -29.835993\n",
      "Train Epoch: 30 [26880/60000 (45%)]\tLoss: -30.062744\n",
      "Train Epoch: 30 [28160/60000 (47%)]\tLoss: -30.104401\n",
      "Train Epoch: 30 [29440/60000 (49%)]\tLoss: -30.272581\n",
      "Train Epoch: 30 [30720/60000 (51%)]\tLoss: -30.239573\n",
      "Train Epoch: 30 [32000/60000 (53%)]\tLoss: -30.251959\n",
      "Train Epoch: 30 [33280/60000 (55%)]\tLoss: -30.059179\n",
      "Train Epoch: 30 [34560/60000 (58%)]\tLoss: -29.778440\n",
      "Train Epoch: 30 [35840/60000 (60%)]\tLoss: -29.860748\n",
      "Train Epoch: 30 [37120/60000 (62%)]\tLoss: -29.999458\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: -29.854824\n",
      "Train Epoch: 30 [39680/60000 (66%)]\tLoss: -29.802942\n",
      "Train Epoch: 30 [40960/60000 (68%)]\tLoss: -30.126850\n",
      "Train Epoch: 30 [42240/60000 (70%)]\tLoss: -30.293604\n",
      "Train Epoch: 30 [43520/60000 (72%)]\tLoss: -29.827312\n",
      "Train Epoch: 30 [44800/60000 (75%)]\tLoss: -30.498949\n",
      "Train Epoch: 30 [46080/60000 (77%)]\tLoss: -30.181751\n",
      "Train Epoch: 30 [47360/60000 (79%)]\tLoss: -30.310833\n",
      "Train Epoch: 30 [48640/60000 (81%)]\tLoss: -29.945675\n",
      "Train Epoch: 30 [49920/60000 (83%)]\tLoss: -29.995129\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: -29.964914\n",
      "Train Epoch: 30 [52480/60000 (87%)]\tLoss: -29.844339\n",
      "Train Epoch: 30 [53760/60000 (90%)]\tLoss: -30.078859\n",
      "Train Epoch: 30 [55040/60000 (92%)]\tLoss: -29.878637\n",
      "Train Epoch: 30 [56320/60000 (94%)]\tLoss: -29.852421\n",
      "Train Epoch: 30 [57600/60000 (96%)]\tLoss: -29.849188\n",
      "Train Epoch: 30 [58880/60000 (98%)]\tLoss: -29.988991\n",
      "====> Epoch: 30 Average loss: -29.9483\n",
      "====> Test set loss: -30.2983\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: -30.132931\n",
      "Train Epoch: 31 [1280/60000 (2%)]\tLoss: -29.975618\n",
      "Train Epoch: 31 [2560/60000 (4%)]\tLoss: -30.157690\n",
      "Train Epoch: 31 [3840/60000 (6%)]\tLoss: -29.925112\n",
      "Train Epoch: 31 [5120/60000 (9%)]\tLoss: -29.668720\n",
      "Train Epoch: 31 [6400/60000 (11%)]\tLoss: -30.002737\n",
      "Train Epoch: 31 [7680/60000 (13%)]\tLoss: -30.427954\n",
      "Train Epoch: 31 [8960/60000 (15%)]\tLoss: -29.736673\n",
      "Train Epoch: 31 [10240/60000 (17%)]\tLoss: -30.143709\n",
      "Train Epoch: 31 [11520/60000 (19%)]\tLoss: -29.872887\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: -30.041960\n",
      "Train Epoch: 31 [14080/60000 (23%)]\tLoss: -30.009701\n",
      "Train Epoch: 31 [15360/60000 (26%)]\tLoss: -29.937988\n",
      "Train Epoch: 31 [16640/60000 (28%)]\tLoss: -30.043554\n",
      "Train Epoch: 31 [17920/60000 (30%)]\tLoss: -29.910389\n",
      "Train Epoch: 31 [19200/60000 (32%)]\tLoss: -30.020109\n",
      "Train Epoch: 31 [20480/60000 (34%)]\tLoss: -29.847551\n",
      "Train Epoch: 31 [21760/60000 (36%)]\tLoss: -29.454071\n",
      "Train Epoch: 31 [23040/60000 (38%)]\tLoss: -29.644432\n",
      "Train Epoch: 31 [24320/60000 (41%)]\tLoss: -29.838223\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: -30.143164\n",
      "Train Epoch: 31 [26880/60000 (45%)]\tLoss: -29.890209\n",
      "Train Epoch: 31 [28160/60000 (47%)]\tLoss: -30.118416\n",
      "Train Epoch: 31 [29440/60000 (49%)]\tLoss: -30.046286\n",
      "Train Epoch: 31 [30720/60000 (51%)]\tLoss: -29.971357\n",
      "Train Epoch: 31 [32000/60000 (53%)]\tLoss: -30.247009\n",
      "Train Epoch: 31 [33280/60000 (55%)]\tLoss: -30.198248\n",
      "Train Epoch: 31 [34560/60000 (58%)]\tLoss: -29.832756\n",
      "Train Epoch: 31 [35840/60000 (60%)]\tLoss: -30.108761\n",
      "Train Epoch: 31 [37120/60000 (62%)]\tLoss: -29.826376\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: -29.972696\n",
      "Train Epoch: 31 [39680/60000 (66%)]\tLoss: -29.700962\n",
      "Train Epoch: 31 [40960/60000 (68%)]\tLoss: -29.736666\n",
      "Train Epoch: 31 [42240/60000 (70%)]\tLoss: -29.912863\n",
      "Train Epoch: 31 [43520/60000 (72%)]\tLoss: -29.927675\n",
      "Train Epoch: 31 [44800/60000 (75%)]\tLoss: -30.043036\n",
      "Train Epoch: 31 [46080/60000 (77%)]\tLoss: -30.154612\n",
      "Train Epoch: 31 [47360/60000 (79%)]\tLoss: -30.222561\n",
      "Train Epoch: 31 [48640/60000 (81%)]\tLoss: -30.066849\n",
      "Train Epoch: 31 [49920/60000 (83%)]\tLoss: -29.772915\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: -30.149033\n",
      "Train Epoch: 31 [52480/60000 (87%)]\tLoss: -30.199060\n",
      "Train Epoch: 31 [53760/60000 (90%)]\tLoss: -30.200073\n",
      "Train Epoch: 31 [55040/60000 (92%)]\tLoss: -29.955412\n",
      "Train Epoch: 31 [56320/60000 (94%)]\tLoss: -29.854805\n",
      "Train Epoch: 31 [57600/60000 (96%)]\tLoss: -30.147671\n",
      "Train Epoch: 31 [58880/60000 (98%)]\tLoss: -30.172699\n",
      "====> Epoch: 31 Average loss: -30.0467\n",
      "====> Test set loss: -30.3672\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: -30.127058\n",
      "Train Epoch: 32 [1280/60000 (2%)]\tLoss: -29.685204\n",
      "Train Epoch: 32 [2560/60000 (4%)]\tLoss: -29.987238\n",
      "Train Epoch: 32 [3840/60000 (6%)]\tLoss: -30.233122\n",
      "Train Epoch: 32 [5120/60000 (9%)]\tLoss: -30.140230\n",
      "Train Epoch: 32 [6400/60000 (11%)]\tLoss: -30.157999\n",
      "Train Epoch: 32 [7680/60000 (13%)]\tLoss: -30.165058\n",
      "Train Epoch: 32 [8960/60000 (15%)]\tLoss: -30.267170\n",
      "Train Epoch: 32 [10240/60000 (17%)]\tLoss: -30.456619\n",
      "Train Epoch: 32 [11520/60000 (19%)]\tLoss: -30.302931\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: -30.163200\n",
      "Train Epoch: 32 [14080/60000 (23%)]\tLoss: -30.257689\n",
      "Train Epoch: 32 [15360/60000 (26%)]\tLoss: -29.807222\n",
      "Train Epoch: 32 [16640/60000 (28%)]\tLoss: -30.025223\n",
      "Train Epoch: 32 [17920/60000 (30%)]\tLoss: -30.581686\n",
      "Train Epoch: 32 [19200/60000 (32%)]\tLoss: -30.089817\n",
      "Train Epoch: 32 [20480/60000 (34%)]\tLoss: -30.396774\n",
      "Train Epoch: 32 [21760/60000 (36%)]\tLoss: -29.991531\n",
      "Train Epoch: 32 [23040/60000 (38%)]\tLoss: -30.040667\n",
      "Train Epoch: 32 [24320/60000 (41%)]\tLoss: -29.838369\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: -30.047537\n",
      "Train Epoch: 32 [26880/60000 (45%)]\tLoss: -30.112902\n",
      "Train Epoch: 32 [28160/60000 (47%)]\tLoss: -30.127260\n",
      "Train Epoch: 32 [29440/60000 (49%)]\tLoss: -30.007496\n",
      "Train Epoch: 32 [30720/60000 (51%)]\tLoss: -29.945154\n",
      "Train Epoch: 32 [32000/60000 (53%)]\tLoss: -30.378092\n",
      "Train Epoch: 32 [33280/60000 (55%)]\tLoss: -30.245556\n",
      "Train Epoch: 32 [34560/60000 (58%)]\tLoss: -30.401184\n",
      "Train Epoch: 32 [35840/60000 (60%)]\tLoss: -29.996428\n",
      "Train Epoch: 32 [37120/60000 (62%)]\tLoss: -30.056353\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: -29.982515\n",
      "Train Epoch: 32 [39680/60000 (66%)]\tLoss: -30.236349\n",
      "Train Epoch: 32 [40960/60000 (68%)]\tLoss: -29.954128\n",
      "Train Epoch: 32 [42240/60000 (70%)]\tLoss: -30.343096\n",
      "Train Epoch: 32 [43520/60000 (72%)]\tLoss: -30.035761\n",
      "Train Epoch: 32 [44800/60000 (75%)]\tLoss: -30.084379\n",
      "Train Epoch: 32 [46080/60000 (77%)]\tLoss: -30.351971\n",
      "Train Epoch: 32 [47360/60000 (79%)]\tLoss: -30.595631\n",
      "Train Epoch: 32 [48640/60000 (81%)]\tLoss: -30.387066\n",
      "Train Epoch: 32 [49920/60000 (83%)]\tLoss: -30.597973\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: -30.526085\n",
      "Train Epoch: 32 [52480/60000 (87%)]\tLoss: -30.174612\n",
      "Train Epoch: 32 [53760/60000 (90%)]\tLoss: -30.267773\n",
      "Train Epoch: 32 [55040/60000 (92%)]\tLoss: -30.232964\n",
      "Train Epoch: 32 [56320/60000 (94%)]\tLoss: -30.368828\n",
      "Train Epoch: 32 [57600/60000 (96%)]\tLoss: -30.045002\n",
      "Train Epoch: 32 [58880/60000 (98%)]\tLoss: -30.434782\n",
      "====> Epoch: 32 Average loss: -30.2042\n",
      "====> Test set loss: -30.6497\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: -30.375479\n",
      "Train Epoch: 33 [1280/60000 (2%)]\tLoss: -30.066828\n",
      "Train Epoch: 33 [2560/60000 (4%)]\tLoss: -30.241714\n",
      "Train Epoch: 33 [3840/60000 (6%)]\tLoss: -30.226452\n",
      "Train Epoch: 33 [5120/60000 (9%)]\tLoss: -30.595005\n",
      "Train Epoch: 33 [6400/60000 (11%)]\tLoss: -30.341825\n",
      "Train Epoch: 33 [7680/60000 (13%)]\tLoss: -30.387127\n",
      "Train Epoch: 33 [8960/60000 (15%)]\tLoss: -30.079239\n",
      "Train Epoch: 33 [10240/60000 (17%)]\tLoss: -29.904686\n",
      "Train Epoch: 33 [11520/60000 (19%)]\tLoss: -30.461231\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: -30.306917\n",
      "Train Epoch: 33 [14080/60000 (23%)]\tLoss: -30.707378\n",
      "Train Epoch: 33 [15360/60000 (26%)]\tLoss: -30.463303\n",
      "Train Epoch: 33 [16640/60000 (28%)]\tLoss: -30.146053\n",
      "Train Epoch: 33 [17920/60000 (30%)]\tLoss: -29.742380\n",
      "Train Epoch: 33 [19200/60000 (32%)]\tLoss: -30.168711\n",
      "Train Epoch: 33 [20480/60000 (34%)]\tLoss: -30.294157\n",
      "Train Epoch: 33 [21760/60000 (36%)]\tLoss: -30.239246\n",
      "Train Epoch: 33 [23040/60000 (38%)]\tLoss: -30.644213\n",
      "Train Epoch: 33 [24320/60000 (41%)]\tLoss: -30.408823\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: -30.257431\n",
      "Train Epoch: 33 [26880/60000 (45%)]\tLoss: -30.170197\n",
      "Train Epoch: 33 [28160/60000 (47%)]\tLoss: -30.013012\n",
      "Train Epoch: 33 [29440/60000 (49%)]\tLoss: -30.255945\n",
      "Train Epoch: 33 [30720/60000 (51%)]\tLoss: -30.140202\n",
      "Train Epoch: 33 [32000/60000 (53%)]\tLoss: -30.264038\n",
      "Train Epoch: 33 [33280/60000 (55%)]\tLoss: -30.634712\n",
      "Train Epoch: 33 [34560/60000 (58%)]\tLoss: -29.659819\n",
      "Train Epoch: 33 [35840/60000 (60%)]\tLoss: -30.285391\n",
      "Train Epoch: 33 [37120/60000 (62%)]\tLoss: -30.396181\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: -30.046890\n",
      "Train Epoch: 33 [39680/60000 (66%)]\tLoss: -30.263744\n",
      "Train Epoch: 33 [40960/60000 (68%)]\tLoss: -30.570959\n",
      "Train Epoch: 33 [42240/60000 (70%)]\tLoss: -30.280813\n",
      "Train Epoch: 33 [43520/60000 (72%)]\tLoss: -30.609953\n",
      "Train Epoch: 33 [44800/60000 (75%)]\tLoss: -30.313923\n",
      "Train Epoch: 33 [46080/60000 (77%)]\tLoss: -30.393064\n",
      "Train Epoch: 33 [47360/60000 (79%)]\tLoss: -30.449455\n",
      "Train Epoch: 33 [48640/60000 (81%)]\tLoss: -30.260481\n",
      "Train Epoch: 33 [49920/60000 (83%)]\tLoss: -30.313559\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: -30.065239\n",
      "Train Epoch: 33 [52480/60000 (87%)]\tLoss: -30.123335\n",
      "Train Epoch: 33 [53760/60000 (90%)]\tLoss: -29.893042\n",
      "Train Epoch: 33 [55040/60000 (92%)]\tLoss: -30.124825\n",
      "Train Epoch: 33 [56320/60000 (94%)]\tLoss: -29.924152\n",
      "Train Epoch: 33 [57600/60000 (96%)]\tLoss: -30.878624\n",
      "Train Epoch: 33 [58880/60000 (98%)]\tLoss: -30.619467\n",
      "====> Epoch: 33 Average loss: -30.2819\n",
      "====> Test set loss: -30.7219\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: -30.599749\n",
      "Train Epoch: 34 [1280/60000 (2%)]\tLoss: -30.017080\n",
      "Train Epoch: 34 [2560/60000 (4%)]\tLoss: -30.654852\n",
      "Train Epoch: 34 [3840/60000 (6%)]\tLoss: -30.046537\n",
      "Train Epoch: 34 [5120/60000 (9%)]\tLoss: -30.246616\n",
      "Train Epoch: 34 [6400/60000 (11%)]\tLoss: -30.366186\n",
      "Train Epoch: 34 [7680/60000 (13%)]\tLoss: -30.328491\n",
      "Train Epoch: 34 [8960/60000 (15%)]\tLoss: -30.551083\n",
      "Train Epoch: 34 [10240/60000 (17%)]\tLoss: -30.153223\n",
      "Train Epoch: 34 [11520/60000 (19%)]\tLoss: -30.572950\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: -30.804543\n",
      "Train Epoch: 34 [14080/60000 (23%)]\tLoss: -30.184530\n",
      "Train Epoch: 34 [15360/60000 (26%)]\tLoss: -30.108274\n",
      "Train Epoch: 34 [16640/60000 (28%)]\tLoss: -30.589310\n",
      "Train Epoch: 34 [17920/60000 (30%)]\tLoss: -30.209812\n",
      "Train Epoch: 34 [19200/60000 (32%)]\tLoss: -29.940145\n",
      "Train Epoch: 34 [20480/60000 (34%)]\tLoss: -30.144358\n",
      "Train Epoch: 34 [21760/60000 (36%)]\tLoss: -30.222723\n",
      "Train Epoch: 34 [23040/60000 (38%)]\tLoss: -30.246183\n",
      "Train Epoch: 34 [24320/60000 (41%)]\tLoss: -30.325672\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: -30.283564\n",
      "Train Epoch: 34 [26880/60000 (45%)]\tLoss: -30.262928\n",
      "Train Epoch: 34 [28160/60000 (47%)]\tLoss: -30.747946\n",
      "Train Epoch: 34 [29440/60000 (49%)]\tLoss: -30.306057\n",
      "Train Epoch: 34 [30720/60000 (51%)]\tLoss: -30.612013\n",
      "Train Epoch: 34 [32000/60000 (53%)]\tLoss: -30.389534\n",
      "Train Epoch: 34 [33280/60000 (55%)]\tLoss: -30.390467\n",
      "Train Epoch: 34 [34560/60000 (58%)]\tLoss: -30.139381\n",
      "Train Epoch: 34 [35840/60000 (60%)]\tLoss: -30.251055\n",
      "Train Epoch: 34 [37120/60000 (62%)]\tLoss: -30.237194\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: -29.830925\n",
      "Train Epoch: 34 [39680/60000 (66%)]\tLoss: -30.822327\n",
      "Train Epoch: 34 [40960/60000 (68%)]\tLoss: -30.509657\n",
      "Train Epoch: 34 [42240/60000 (70%)]\tLoss: -30.696928\n",
      "Train Epoch: 34 [43520/60000 (72%)]\tLoss: -30.527657\n",
      "Train Epoch: 34 [44800/60000 (75%)]\tLoss: -30.061466\n",
      "Train Epoch: 34 [46080/60000 (77%)]\tLoss: -30.188429\n",
      "Train Epoch: 34 [47360/60000 (79%)]\tLoss: -30.303808\n",
      "Train Epoch: 34 [48640/60000 (81%)]\tLoss: -30.489563\n",
      "Train Epoch: 34 [49920/60000 (83%)]\tLoss: -30.056442\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: -30.359743\n",
      "Train Epoch: 34 [52480/60000 (87%)]\tLoss: -30.501152\n",
      "Train Epoch: 34 [53760/60000 (90%)]\tLoss: -30.402246\n",
      "Train Epoch: 34 [55040/60000 (92%)]\tLoss: -30.119797\n",
      "Train Epoch: 34 [56320/60000 (94%)]\tLoss: -30.984646\n",
      "Train Epoch: 34 [57600/60000 (96%)]\tLoss: -29.709679\n",
      "Train Epoch: 34 [58880/60000 (98%)]\tLoss: -29.920179\n",
      "====> Epoch: 34 Average loss: -30.2573\n",
      "====> Test set loss: -30.3758\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: -30.151901\n",
      "Train Epoch: 35 [1280/60000 (2%)]\tLoss: -30.350399\n",
      "Train Epoch: 35 [2560/60000 (4%)]\tLoss: -30.259266\n",
      "Train Epoch: 35 [3840/60000 (6%)]\tLoss: -30.496519\n",
      "Train Epoch: 35 [5120/60000 (9%)]\tLoss: -30.450689\n",
      "Train Epoch: 35 [6400/60000 (11%)]\tLoss: -30.364353\n",
      "Train Epoch: 35 [7680/60000 (13%)]\tLoss: -30.263481\n",
      "Train Epoch: 35 [8960/60000 (15%)]\tLoss: -30.033077\n",
      "Train Epoch: 35 [10240/60000 (17%)]\tLoss: -30.438818\n",
      "Train Epoch: 35 [11520/60000 (19%)]\tLoss: -30.488482\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: -29.878117\n",
      "Train Epoch: 35 [14080/60000 (23%)]\tLoss: -29.981573\n",
      "Train Epoch: 35 [15360/60000 (26%)]\tLoss: -30.384676\n",
      "Train Epoch: 35 [16640/60000 (28%)]\tLoss: -30.756615\n",
      "Train Epoch: 35 [17920/60000 (30%)]\tLoss: -30.346865\n",
      "Train Epoch: 35 [19200/60000 (32%)]\tLoss: -30.488426\n",
      "Train Epoch: 35 [20480/60000 (34%)]\tLoss: -30.216883\n",
      "Train Epoch: 35 [21760/60000 (36%)]\tLoss: -30.034138\n",
      "Train Epoch: 35 [23040/60000 (38%)]\tLoss: -30.115583\n",
      "Train Epoch: 35 [24320/60000 (41%)]\tLoss: -30.226742\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: -30.063253\n",
      "Train Epoch: 35 [26880/60000 (45%)]\tLoss: -29.884315\n",
      "Train Epoch: 35 [28160/60000 (47%)]\tLoss: -30.333698\n",
      "Train Epoch: 35 [29440/60000 (49%)]\tLoss: -30.049267\n",
      "Train Epoch: 35 [30720/60000 (51%)]\tLoss: -30.325344\n",
      "Train Epoch: 35 [32000/60000 (53%)]\tLoss: -29.958021\n",
      "Train Epoch: 35 [33280/60000 (55%)]\tLoss: -30.141304\n",
      "Train Epoch: 35 [34560/60000 (58%)]\tLoss: -30.254704\n",
      "Train Epoch: 35 [35840/60000 (60%)]\tLoss: -30.272711\n",
      "Train Epoch: 35 [37120/60000 (62%)]\tLoss: -30.093065\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: -30.415461\n",
      "Train Epoch: 35 [39680/60000 (66%)]\tLoss: -30.097094\n",
      "Train Epoch: 35 [40960/60000 (68%)]\tLoss: -30.350576\n",
      "Train Epoch: 35 [42240/60000 (70%)]\tLoss: -30.051058\n",
      "Train Epoch: 35 [43520/60000 (72%)]\tLoss: -30.038357\n",
      "Train Epoch: 35 [44800/60000 (75%)]\tLoss: -30.042622\n",
      "Train Epoch: 35 [46080/60000 (77%)]\tLoss: -29.857784\n",
      "Train Epoch: 35 [47360/60000 (79%)]\tLoss: -30.477331\n",
      "Train Epoch: 35 [48640/60000 (81%)]\tLoss: -30.267824\n",
      "Train Epoch: 35 [49920/60000 (83%)]\tLoss: -29.992874\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: -30.182304\n",
      "Train Epoch: 35 [52480/60000 (87%)]\tLoss: -30.268084\n",
      "Train Epoch: 35 [53760/60000 (90%)]\tLoss: -29.598267\n",
      "Train Epoch: 35 [55040/60000 (92%)]\tLoss: -29.876499\n",
      "Train Epoch: 35 [56320/60000 (94%)]\tLoss: -30.081261\n",
      "Train Epoch: 35 [57600/60000 (96%)]\tLoss: -30.361185\n",
      "Train Epoch: 35 [58880/60000 (98%)]\tLoss: -30.790625\n",
      "====> Epoch: 35 Average loss: -30.2618\n",
      "====> Test set loss: -30.6804\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: -30.203310\n",
      "Train Epoch: 36 [1280/60000 (2%)]\tLoss: -30.297768\n",
      "Train Epoch: 36 [2560/60000 (4%)]\tLoss: -30.493357\n",
      "Train Epoch: 36 [3840/60000 (6%)]\tLoss: -30.493082\n",
      "Train Epoch: 36 [5120/60000 (9%)]\tLoss: -30.771360\n",
      "Train Epoch: 36 [6400/60000 (11%)]\tLoss: -30.656591\n",
      "Train Epoch: 36 [7680/60000 (13%)]\tLoss: -29.947100\n",
      "Train Epoch: 36 [8960/60000 (15%)]\tLoss: -30.380499\n",
      "Train Epoch: 36 [10240/60000 (17%)]\tLoss: -30.665392\n",
      "Train Epoch: 36 [11520/60000 (19%)]\tLoss: -30.308743\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: -30.105984\n",
      "Train Epoch: 36 [14080/60000 (23%)]\tLoss: -29.973860\n",
      "Train Epoch: 36 [15360/60000 (26%)]\tLoss: -30.307539\n",
      "Train Epoch: 36 [16640/60000 (28%)]\tLoss: -30.404375\n",
      "Train Epoch: 36 [17920/60000 (30%)]\tLoss: -30.189354\n",
      "Train Epoch: 36 [19200/60000 (32%)]\tLoss: -30.222925\n",
      "Train Epoch: 36 [20480/60000 (34%)]\tLoss: -30.316593\n",
      "Train Epoch: 36 [21760/60000 (36%)]\tLoss: -30.339748\n",
      "Train Epoch: 36 [23040/60000 (38%)]\tLoss: -29.847631\n",
      "Train Epoch: 36 [24320/60000 (41%)]\tLoss: -30.259354\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: -30.525414\n",
      "Train Epoch: 36 [26880/60000 (45%)]\tLoss: -30.119339\n",
      "Train Epoch: 36 [28160/60000 (47%)]\tLoss: -30.300451\n",
      "Train Epoch: 36 [29440/60000 (49%)]\tLoss: -30.323257\n",
      "Train Epoch: 36 [30720/60000 (51%)]\tLoss: -30.137033\n",
      "Train Epoch: 36 [32000/60000 (53%)]\tLoss: -30.420776\n",
      "Train Epoch: 36 [33280/60000 (55%)]\tLoss: -30.324097\n",
      "Train Epoch: 36 [34560/60000 (58%)]\tLoss: -30.494991\n",
      "Train Epoch: 36 [35840/60000 (60%)]\tLoss: -30.278116\n",
      "Train Epoch: 36 [37120/60000 (62%)]\tLoss: -30.086617\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: -30.039549\n",
      "Train Epoch: 36 [39680/60000 (66%)]\tLoss: -30.181936\n",
      "Train Epoch: 36 [40960/60000 (68%)]\tLoss: -30.396536\n",
      "Train Epoch: 36 [42240/60000 (70%)]\tLoss: -30.590145\n",
      "Train Epoch: 36 [43520/60000 (72%)]\tLoss: -30.371384\n",
      "Train Epoch: 36 [44800/60000 (75%)]\tLoss: -30.456409\n",
      "Train Epoch: 36 [46080/60000 (77%)]\tLoss: -30.202667\n",
      "Train Epoch: 36 [47360/60000 (79%)]\tLoss: -30.772236\n",
      "Train Epoch: 36 [48640/60000 (81%)]\tLoss: -30.075176\n",
      "Train Epoch: 36 [49920/60000 (83%)]\tLoss: -30.240479\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: -30.259562\n",
      "Train Epoch: 36 [52480/60000 (87%)]\tLoss: -30.302067\n",
      "Train Epoch: 36 [53760/60000 (90%)]\tLoss: -30.099968\n",
      "Train Epoch: 36 [55040/60000 (92%)]\tLoss: -30.141300\n",
      "Train Epoch: 36 [56320/60000 (94%)]\tLoss: -30.070845\n",
      "Train Epoch: 36 [57600/60000 (96%)]\tLoss: -30.299080\n",
      "Train Epoch: 36 [58880/60000 (98%)]\tLoss: -30.314680\n",
      "====> Epoch: 36 Average loss: -30.2851\n",
      "====> Test set loss: -30.6723\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: -30.060688\n",
      "Train Epoch: 37 [1280/60000 (2%)]\tLoss: -30.696672\n",
      "Train Epoch: 37 [2560/60000 (4%)]\tLoss: -30.473984\n",
      "Train Epoch: 37 [3840/60000 (6%)]\tLoss: -30.660391\n",
      "Train Epoch: 37 [5120/60000 (9%)]\tLoss: -30.025694\n",
      "Train Epoch: 37 [6400/60000 (11%)]\tLoss: -30.608084\n",
      "Train Epoch: 37 [7680/60000 (13%)]\tLoss: -30.201326\n",
      "Train Epoch: 37 [8960/60000 (15%)]\tLoss: -30.467730\n",
      "Train Epoch: 37 [10240/60000 (17%)]\tLoss: -30.006376\n",
      "Train Epoch: 37 [11520/60000 (19%)]\tLoss: -30.560787\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: -30.460382\n",
      "Train Epoch: 37 [14080/60000 (23%)]\tLoss: -30.518152\n",
      "Train Epoch: 37 [15360/60000 (26%)]\tLoss: -30.555458\n",
      "Train Epoch: 37 [16640/60000 (28%)]\tLoss: -30.286844\n",
      "Train Epoch: 37 [17920/60000 (30%)]\tLoss: -30.588900\n",
      "Train Epoch: 37 [19200/60000 (32%)]\tLoss: -30.319281\n",
      "Train Epoch: 37 [20480/60000 (34%)]\tLoss: -30.340548\n",
      "Train Epoch: 37 [21760/60000 (36%)]\tLoss: -30.331158\n",
      "Train Epoch: 37 [23040/60000 (38%)]\tLoss: -29.987202\n",
      "Train Epoch: 37 [24320/60000 (41%)]\tLoss: -30.616259\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: -30.095385\n",
      "Train Epoch: 37 [26880/60000 (45%)]\tLoss: -30.039801\n",
      "Train Epoch: 37 [28160/60000 (47%)]\tLoss: -30.381498\n",
      "Train Epoch: 37 [29440/60000 (49%)]\tLoss: -30.195736\n",
      "Train Epoch: 37 [30720/60000 (51%)]\tLoss: -30.124975\n",
      "Train Epoch: 37 [32000/60000 (53%)]\tLoss: -30.264500\n",
      "Train Epoch: 37 [33280/60000 (55%)]\tLoss: -29.949238\n",
      "Train Epoch: 37 [34560/60000 (58%)]\tLoss: -30.142591\n",
      "Train Epoch: 37 [35840/60000 (60%)]\tLoss: -30.199291\n",
      "Train Epoch: 37 [37120/60000 (62%)]\tLoss: -30.201929\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: -30.063755\n",
      "Train Epoch: 37 [39680/60000 (66%)]\tLoss: -30.537872\n",
      "Train Epoch: 37 [40960/60000 (68%)]\tLoss: -29.978041\n",
      "Train Epoch: 37 [42240/60000 (70%)]\tLoss: -30.052279\n",
      "Train Epoch: 37 [43520/60000 (72%)]\tLoss: -29.996508\n",
      "Train Epoch: 37 [44800/60000 (75%)]\tLoss: -30.324612\n",
      "Train Epoch: 37 [46080/60000 (77%)]\tLoss: -30.149330\n",
      "Train Epoch: 37 [47360/60000 (79%)]\tLoss: -30.351038\n",
      "Train Epoch: 37 [48640/60000 (81%)]\tLoss: -30.560995\n",
      "Train Epoch: 37 [49920/60000 (83%)]\tLoss: -30.218401\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: -30.146980\n",
      "Train Epoch: 37 [52480/60000 (87%)]\tLoss: -30.335711\n",
      "Train Epoch: 37 [53760/60000 (90%)]\tLoss: -30.280485\n",
      "Train Epoch: 37 [55040/60000 (92%)]\tLoss: -30.686432\n",
      "Train Epoch: 37 [56320/60000 (94%)]\tLoss: -30.382961\n",
      "Train Epoch: 37 [57600/60000 (96%)]\tLoss: -30.023573\n",
      "Train Epoch: 37 [58880/60000 (98%)]\tLoss: -30.744165\n",
      "====> Epoch: 37 Average loss: -30.2567\n",
      "====> Test set loss: -30.5732\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: -30.269299\n",
      "Train Epoch: 38 [1280/60000 (2%)]\tLoss: -30.293243\n",
      "Train Epoch: 38 [2560/60000 (4%)]\tLoss: -30.015558\n",
      "Train Epoch: 38 [3840/60000 (6%)]\tLoss: -30.315710\n",
      "Train Epoch: 38 [5120/60000 (9%)]\tLoss: -30.164845\n",
      "Train Epoch: 38 [6400/60000 (11%)]\tLoss: -29.943951\n",
      "Train Epoch: 38 [7680/60000 (13%)]\tLoss: -30.236809\n",
      "Train Epoch: 38 [8960/60000 (15%)]\tLoss: -29.979059\n",
      "Train Epoch: 38 [10240/60000 (17%)]\tLoss: -30.050047\n",
      "Train Epoch: 38 [11520/60000 (19%)]\tLoss: -29.952024\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: -29.927082\n",
      "Train Epoch: 38 [14080/60000 (23%)]\tLoss: -30.223921\n",
      "Train Epoch: 38 [15360/60000 (26%)]\tLoss: -30.017704\n",
      "Train Epoch: 38 [16640/60000 (28%)]\tLoss: -29.461489\n",
      "Train Epoch: 38 [17920/60000 (30%)]\tLoss: -30.358801\n",
      "Train Epoch: 38 [19200/60000 (32%)]\tLoss: -30.452723\n",
      "Train Epoch: 38 [20480/60000 (34%)]\tLoss: -30.486580\n",
      "Train Epoch: 38 [21760/60000 (36%)]\tLoss: -29.967417\n",
      "Train Epoch: 38 [23040/60000 (38%)]\tLoss: -30.640074\n",
      "Train Epoch: 38 [24320/60000 (41%)]\tLoss: -30.365158\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: -30.084196\n",
      "Train Epoch: 38 [26880/60000 (45%)]\tLoss: -30.386026\n",
      "Train Epoch: 38 [28160/60000 (47%)]\tLoss: -30.078587\n",
      "Train Epoch: 38 [29440/60000 (49%)]\tLoss: -30.197027\n",
      "Train Epoch: 38 [30720/60000 (51%)]\tLoss: -29.946947\n",
      "Train Epoch: 38 [32000/60000 (53%)]\tLoss: -30.426809\n",
      "Train Epoch: 38 [33280/60000 (55%)]\tLoss: -30.608450\n",
      "Train Epoch: 38 [34560/60000 (58%)]\tLoss: -30.165390\n",
      "Train Epoch: 38 [35840/60000 (60%)]\tLoss: -30.846224\n",
      "Train Epoch: 38 [37120/60000 (62%)]\tLoss: -30.498413\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: -30.046888\n",
      "Train Epoch: 38 [39680/60000 (66%)]\tLoss: -29.867464\n",
      "Train Epoch: 38 [40960/60000 (68%)]\tLoss: -30.447317\n",
      "Train Epoch: 38 [42240/60000 (70%)]\tLoss: -30.434107\n",
      "Train Epoch: 38 [43520/60000 (72%)]\tLoss: -29.980436\n",
      "Train Epoch: 38 [44800/60000 (75%)]\tLoss: -30.291357\n",
      "Train Epoch: 38 [46080/60000 (77%)]\tLoss: -30.105257\n",
      "Train Epoch: 38 [47360/60000 (79%)]\tLoss: -30.355976\n",
      "Train Epoch: 38 [48640/60000 (81%)]\tLoss: -30.423805\n",
      "Train Epoch: 38 [49920/60000 (83%)]\tLoss: -30.543079\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: -30.069712\n",
      "Train Epoch: 38 [52480/60000 (87%)]\tLoss: -30.460865\n",
      "Train Epoch: 38 [53760/60000 (90%)]\tLoss: -30.557590\n",
      "Train Epoch: 38 [55040/60000 (92%)]\tLoss: -30.258110\n",
      "Train Epoch: 38 [56320/60000 (94%)]\tLoss: -29.894901\n",
      "Train Epoch: 38 [57600/60000 (96%)]\tLoss: -30.333832\n",
      "Train Epoch: 38 [58880/60000 (98%)]\tLoss: -30.197472\n",
      "====> Epoch: 38 Average loss: -30.2552\n",
      "====> Test set loss: -30.7465\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: -30.170702\n",
      "Train Epoch: 39 [1280/60000 (2%)]\tLoss: -30.462492\n",
      "Train Epoch: 39 [2560/60000 (4%)]\tLoss: -30.333799\n",
      "Train Epoch: 39 [3840/60000 (6%)]\tLoss: -30.233053\n",
      "Train Epoch: 39 [5120/60000 (9%)]\tLoss: -30.557259\n",
      "Train Epoch: 39 [6400/60000 (11%)]\tLoss: -30.706091\n",
      "Train Epoch: 39 [7680/60000 (13%)]\tLoss: -30.115582\n",
      "Train Epoch: 39 [8960/60000 (15%)]\tLoss: -30.219818\n",
      "Train Epoch: 39 [10240/60000 (17%)]\tLoss: -30.207764\n",
      "Train Epoch: 39 [11520/60000 (19%)]\tLoss: -30.441877\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: -29.975775\n",
      "Train Epoch: 39 [14080/60000 (23%)]\tLoss: -29.850466\n",
      "Train Epoch: 39 [15360/60000 (26%)]\tLoss: -30.016836\n",
      "Train Epoch: 39 [16640/60000 (28%)]\tLoss: -30.200447\n",
      "Train Epoch: 39 [17920/60000 (30%)]\tLoss: -30.278885\n",
      "Train Epoch: 39 [19200/60000 (32%)]\tLoss: -29.969669\n",
      "Train Epoch: 39 [20480/60000 (34%)]\tLoss: -30.398375\n",
      "Train Epoch: 39 [21760/60000 (36%)]\tLoss: -30.312223\n",
      "Train Epoch: 39 [23040/60000 (38%)]\tLoss: -30.030964\n",
      "Train Epoch: 39 [24320/60000 (41%)]\tLoss: -29.949133\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: -30.562721\n",
      "Train Epoch: 39 [26880/60000 (45%)]\tLoss: -30.310604\n",
      "Train Epoch: 39 [28160/60000 (47%)]\tLoss: -30.379847\n",
      "Train Epoch: 39 [29440/60000 (49%)]\tLoss: -30.047283\n",
      "Train Epoch: 39 [30720/60000 (51%)]\tLoss: -30.029274\n",
      "Train Epoch: 39 [32000/60000 (53%)]\tLoss: -30.176392\n",
      "Train Epoch: 39 [33280/60000 (55%)]\tLoss: -30.025946\n",
      "Train Epoch: 39 [34560/60000 (58%)]\tLoss: -30.029819\n",
      "Train Epoch: 39 [35840/60000 (60%)]\tLoss: -30.107151\n",
      "Train Epoch: 39 [37120/60000 (62%)]\tLoss: -30.248751\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: -30.180054\n",
      "Train Epoch: 39 [39680/60000 (66%)]\tLoss: -29.507954\n",
      "Train Epoch: 39 [40960/60000 (68%)]\tLoss: -30.001961\n",
      "Train Epoch: 39 [42240/60000 (70%)]\tLoss: -29.981411\n",
      "Train Epoch: 39 [43520/60000 (72%)]\tLoss: -29.831579\n",
      "Train Epoch: 39 [44800/60000 (75%)]\tLoss: -30.305801\n",
      "Train Epoch: 39 [46080/60000 (77%)]\tLoss: -30.267540\n",
      "Train Epoch: 39 [47360/60000 (79%)]\tLoss: -30.232513\n",
      "Train Epoch: 39 [48640/60000 (81%)]\tLoss: -29.798660\n",
      "Train Epoch: 39 [49920/60000 (83%)]\tLoss: -30.661972\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: -30.032856\n",
      "Train Epoch: 39 [52480/60000 (87%)]\tLoss: -30.835468\n",
      "Train Epoch: 39 [53760/60000 (90%)]\tLoss: -29.936256\n",
      "Train Epoch: 39 [55040/60000 (92%)]\tLoss: -30.330877\n",
      "Train Epoch: 39 [56320/60000 (94%)]\tLoss: -30.079046\n",
      "Train Epoch: 39 [57600/60000 (96%)]\tLoss: -29.990396\n",
      "Train Epoch: 39 [58880/60000 (98%)]\tLoss: -30.179834\n",
      "====> Epoch: 39 Average loss: -30.1937\n",
      "====> Test set loss: -30.6484\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: -30.071037\n",
      "Train Epoch: 40 [1280/60000 (2%)]\tLoss: -30.180695\n",
      "Train Epoch: 40 [2560/60000 (4%)]\tLoss: -30.062511\n",
      "Train Epoch: 40 [3840/60000 (6%)]\tLoss: -30.412136\n",
      "Train Epoch: 40 [5120/60000 (9%)]\tLoss: -30.406294\n",
      "Train Epoch: 40 [6400/60000 (11%)]\tLoss: -30.275555\n",
      "Train Epoch: 40 [7680/60000 (13%)]\tLoss: -29.790970\n",
      "Train Epoch: 40 [8960/60000 (15%)]\tLoss: -30.065405\n",
      "Train Epoch: 40 [10240/60000 (17%)]\tLoss: -30.165007\n",
      "Train Epoch: 40 [11520/60000 (19%)]\tLoss: -30.333580\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: -30.010658\n",
      "Train Epoch: 40 [14080/60000 (23%)]\tLoss: -30.430153\n",
      "Train Epoch: 40 [15360/60000 (26%)]\tLoss: -30.006094\n",
      "Train Epoch: 40 [16640/60000 (28%)]\tLoss: -30.519184\n",
      "Train Epoch: 40 [17920/60000 (30%)]\tLoss: -30.442579\n",
      "Train Epoch: 40 [19200/60000 (32%)]\tLoss: -30.281610\n",
      "Train Epoch: 40 [20480/60000 (34%)]\tLoss: -30.272362\n",
      "Train Epoch: 40 [21760/60000 (36%)]\tLoss: -30.274784\n",
      "Train Epoch: 40 [23040/60000 (38%)]\tLoss: -30.157707\n",
      "Train Epoch: 40 [24320/60000 (41%)]\tLoss: -30.322281\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: -30.364798\n",
      "Train Epoch: 40 [26880/60000 (45%)]\tLoss: -30.115990\n",
      "Train Epoch: 40 [28160/60000 (47%)]\tLoss: -30.148891\n",
      "Train Epoch: 40 [29440/60000 (49%)]\tLoss: -30.420795\n",
      "Train Epoch: 40 [30720/60000 (51%)]\tLoss: -30.550714\n",
      "Train Epoch: 40 [32000/60000 (53%)]\tLoss: -30.211550\n",
      "Train Epoch: 40 [33280/60000 (55%)]\tLoss: -29.861645\n",
      "Train Epoch: 40 [34560/60000 (58%)]\tLoss: -30.174004\n",
      "Train Epoch: 40 [35840/60000 (60%)]\tLoss: -29.907011\n",
      "Train Epoch: 40 [37120/60000 (62%)]\tLoss: -30.752502\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: -30.552908\n",
      "Train Epoch: 40 [39680/60000 (66%)]\tLoss: -30.620487\n",
      "Train Epoch: 40 [40960/60000 (68%)]\tLoss: -30.710249\n",
      "Train Epoch: 40 [42240/60000 (70%)]\tLoss: -30.426886\n",
      "Train Epoch: 40 [43520/60000 (72%)]\tLoss: -30.319054\n",
      "Train Epoch: 40 [44800/60000 (75%)]\tLoss: -30.024036\n",
      "Train Epoch: 40 [46080/60000 (77%)]\tLoss: -30.540600\n",
      "Train Epoch: 40 [47360/60000 (79%)]\tLoss: -30.546185\n",
      "Train Epoch: 40 [48640/60000 (81%)]\tLoss: -30.405184\n",
      "Train Epoch: 40 [49920/60000 (83%)]\tLoss: -30.486712\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: -30.046223\n",
      "Train Epoch: 40 [52480/60000 (87%)]\tLoss: -30.224030\n",
      "Train Epoch: 40 [53760/60000 (90%)]\tLoss: -30.421566\n",
      "Train Epoch: 40 [55040/60000 (92%)]\tLoss: -30.426970\n",
      "Train Epoch: 40 [56320/60000 (94%)]\tLoss: -30.025305\n",
      "Train Epoch: 40 [57600/60000 (96%)]\tLoss: -29.991394\n",
      "Train Epoch: 40 [58880/60000 (98%)]\tLoss: -30.375401\n",
      "====> Epoch: 40 Average loss: -30.2828\n",
      "====> Test set loss: -30.4988\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: -30.391993\n",
      "Train Epoch: 41 [1280/60000 (2%)]\tLoss: -30.265713\n",
      "Train Epoch: 41 [2560/60000 (4%)]\tLoss: -30.445238\n",
      "Train Epoch: 41 [3840/60000 (6%)]\tLoss: -30.395899\n",
      "Train Epoch: 41 [5120/60000 (9%)]\tLoss: -30.689604\n",
      "Train Epoch: 41 [6400/60000 (11%)]\tLoss: -30.094009\n",
      "Train Epoch: 41 [7680/60000 (13%)]\tLoss: -30.173618\n",
      "Train Epoch: 41 [8960/60000 (15%)]\tLoss: -30.281586\n",
      "Train Epoch: 41 [10240/60000 (17%)]\tLoss: -30.511671\n",
      "Train Epoch: 41 [11520/60000 (19%)]\tLoss: -30.291822\n",
      "Train Epoch: 41 [12800/60000 (21%)]\tLoss: -30.243393\n",
      "Train Epoch: 41 [14080/60000 (23%)]\tLoss: -30.100508\n",
      "Train Epoch: 41 [15360/60000 (26%)]\tLoss: -30.636381\n",
      "Train Epoch: 41 [16640/60000 (28%)]\tLoss: -30.703960\n",
      "Train Epoch: 41 [17920/60000 (30%)]\tLoss: -30.435631\n",
      "Train Epoch: 41 [19200/60000 (32%)]\tLoss: -30.301601\n",
      "Train Epoch: 41 [20480/60000 (34%)]\tLoss: -30.291643\n",
      "Train Epoch: 41 [21760/60000 (36%)]\tLoss: -30.330158\n",
      "Train Epoch: 41 [23040/60000 (38%)]\tLoss: -30.703712\n",
      "Train Epoch: 41 [24320/60000 (41%)]\tLoss: -30.455166\n",
      "Train Epoch: 41 [25600/60000 (43%)]\tLoss: -30.135462\n",
      "Train Epoch: 41 [26880/60000 (45%)]\tLoss: -30.484928\n",
      "Train Epoch: 41 [28160/60000 (47%)]\tLoss: -30.224890\n",
      "Train Epoch: 41 [29440/60000 (49%)]\tLoss: -30.718840\n",
      "Train Epoch: 41 [30720/60000 (51%)]\tLoss: -30.097181\n",
      "Train Epoch: 41 [32000/60000 (53%)]\tLoss: -30.568357\n",
      "Train Epoch: 41 [33280/60000 (55%)]\tLoss: -30.533545\n",
      "Train Epoch: 41 [34560/60000 (58%)]\tLoss: -30.637794\n",
      "Train Epoch: 41 [35840/60000 (60%)]\tLoss: -30.512325\n",
      "Train Epoch: 41 [37120/60000 (62%)]\tLoss: -30.184816\n",
      "Train Epoch: 41 [38400/60000 (64%)]\tLoss: -30.451826\n",
      "Train Epoch: 41 [39680/60000 (66%)]\tLoss: -30.388721\n",
      "Train Epoch: 41 [40960/60000 (68%)]\tLoss: -30.501886\n",
      "Train Epoch: 41 [42240/60000 (70%)]\tLoss: -30.477484\n",
      "Train Epoch: 41 [43520/60000 (72%)]\tLoss: -30.360167\n",
      "Train Epoch: 41 [44800/60000 (75%)]\tLoss: -30.337263\n",
      "Train Epoch: 41 [46080/60000 (77%)]\tLoss: -31.114096\n",
      "Train Epoch: 41 [47360/60000 (79%)]\tLoss: -30.239038\n",
      "Train Epoch: 41 [48640/60000 (81%)]\tLoss: -30.172092\n",
      "Train Epoch: 41 [49920/60000 (83%)]\tLoss: -30.674055\n",
      "Train Epoch: 41 [51200/60000 (85%)]\tLoss: -30.234205\n",
      "Train Epoch: 41 [52480/60000 (87%)]\tLoss: -30.362135\n",
      "Train Epoch: 41 [53760/60000 (90%)]\tLoss: -30.797478\n",
      "Train Epoch: 41 [55040/60000 (92%)]\tLoss: -30.048222\n",
      "Train Epoch: 41 [56320/60000 (94%)]\tLoss: -30.574518\n",
      "Train Epoch: 41 [57600/60000 (96%)]\tLoss: -30.573320\n",
      "Train Epoch: 41 [58880/60000 (98%)]\tLoss: -30.455029\n",
      "====> Epoch: 41 Average loss: -30.4076\n",
      "====> Test set loss: -30.7707\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: -30.352997\n",
      "Train Epoch: 42 [1280/60000 (2%)]\tLoss: -30.821339\n",
      "Train Epoch: 42 [2560/60000 (4%)]\tLoss: -30.551428\n",
      "Train Epoch: 42 [3840/60000 (6%)]\tLoss: -30.554811\n",
      "Train Epoch: 42 [5120/60000 (9%)]\tLoss: -30.113535\n",
      "Train Epoch: 42 [6400/60000 (11%)]\tLoss: -30.928362\n",
      "Train Epoch: 42 [7680/60000 (13%)]\tLoss: -30.677599\n",
      "Train Epoch: 42 [8960/60000 (15%)]\tLoss: -30.422518\n",
      "Train Epoch: 42 [10240/60000 (17%)]\tLoss: -29.974627\n",
      "Train Epoch: 42 [11520/60000 (19%)]\tLoss: -30.173025\n",
      "Train Epoch: 42 [12800/60000 (21%)]\tLoss: -30.411930\n",
      "Train Epoch: 42 [14080/60000 (23%)]\tLoss: -30.590425\n",
      "Train Epoch: 42 [15360/60000 (26%)]\tLoss: -30.383659\n",
      "Train Epoch: 42 [16640/60000 (28%)]\tLoss: -30.528498\n",
      "Train Epoch: 42 [17920/60000 (30%)]\tLoss: -30.529682\n",
      "Train Epoch: 42 [19200/60000 (32%)]\tLoss: -30.740946\n",
      "Train Epoch: 42 [20480/60000 (34%)]\tLoss: -30.237282\n",
      "Train Epoch: 42 [21760/60000 (36%)]\tLoss: -30.476900\n",
      "Train Epoch: 42 [23040/60000 (38%)]\tLoss: -30.702435\n",
      "Train Epoch: 42 [24320/60000 (41%)]\tLoss: -30.459305\n",
      "Train Epoch: 42 [25600/60000 (43%)]\tLoss: -31.008440\n",
      "Train Epoch: 42 [26880/60000 (45%)]\tLoss: -30.832470\n",
      "Train Epoch: 42 [28160/60000 (47%)]\tLoss: -30.463638\n",
      "Train Epoch: 42 [29440/60000 (49%)]\tLoss: -30.790367\n",
      "Train Epoch: 42 [30720/60000 (51%)]\tLoss: -30.566734\n",
      "Train Epoch: 42 [32000/60000 (53%)]\tLoss: -30.664051\n",
      "Train Epoch: 42 [33280/60000 (55%)]\tLoss: -30.601612\n",
      "Train Epoch: 42 [34560/60000 (58%)]\tLoss: -30.939552\n",
      "Train Epoch: 42 [35840/60000 (60%)]\tLoss: -30.459721\n",
      "Train Epoch: 42 [37120/60000 (62%)]\tLoss: -30.689241\n",
      "Train Epoch: 42 [38400/60000 (64%)]\tLoss: -30.756302\n",
      "Train Epoch: 42 [39680/60000 (66%)]\tLoss: -30.710499\n",
      "Train Epoch: 42 [40960/60000 (68%)]\tLoss: -29.970898\n",
      "Train Epoch: 42 [42240/60000 (70%)]\tLoss: -30.419037\n",
      "Train Epoch: 42 [43520/60000 (72%)]\tLoss: -31.075171\n",
      "Train Epoch: 42 [44800/60000 (75%)]\tLoss: -30.530546\n",
      "Train Epoch: 42 [46080/60000 (77%)]\tLoss: -30.592609\n",
      "Train Epoch: 42 [47360/60000 (79%)]\tLoss: -30.550226\n",
      "Train Epoch: 42 [48640/60000 (81%)]\tLoss: -30.616638\n",
      "Train Epoch: 42 [49920/60000 (83%)]\tLoss: -30.558653\n",
      "Train Epoch: 42 [51200/60000 (85%)]\tLoss: -30.033186\n",
      "Train Epoch: 42 [52480/60000 (87%)]\tLoss: -30.735228\n",
      "Train Epoch: 42 [53760/60000 (90%)]\tLoss: -30.629128\n",
      "Train Epoch: 42 [55040/60000 (92%)]\tLoss: -30.539095\n",
      "Train Epoch: 42 [56320/60000 (94%)]\tLoss: -30.440044\n",
      "Train Epoch: 42 [57600/60000 (96%)]\tLoss: -30.225428\n",
      "Train Epoch: 42 [58880/60000 (98%)]\tLoss: -30.670824\n",
      "====> Epoch: 42 Average loss: -30.5294\n",
      "====> Test set loss: -30.9112\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: -30.937338\n",
      "Train Epoch: 43 [1280/60000 (2%)]\tLoss: -30.320280\n",
      "Train Epoch: 43 [2560/60000 (4%)]\tLoss: -30.801346\n",
      "Train Epoch: 43 [3840/60000 (6%)]\tLoss: -30.887802\n",
      "Train Epoch: 43 [5120/60000 (9%)]\tLoss: -30.665546\n",
      "Train Epoch: 43 [6400/60000 (11%)]\tLoss: -30.236090\n",
      "Train Epoch: 43 [7680/60000 (13%)]\tLoss: -30.647663\n",
      "Train Epoch: 43 [8960/60000 (15%)]\tLoss: -30.357357\n",
      "Train Epoch: 43 [10240/60000 (17%)]\tLoss: -31.053207\n",
      "Train Epoch: 43 [11520/60000 (19%)]\tLoss: -30.584356\n",
      "Train Epoch: 43 [12800/60000 (21%)]\tLoss: -30.539141\n",
      "Train Epoch: 43 [14080/60000 (23%)]\tLoss: -30.911177\n",
      "Train Epoch: 43 [15360/60000 (26%)]\tLoss: -30.614187\n",
      "Train Epoch: 43 [16640/60000 (28%)]\tLoss: -30.410645\n",
      "Train Epoch: 43 [17920/60000 (30%)]\tLoss: -30.216618\n",
      "Train Epoch: 43 [19200/60000 (32%)]\tLoss: -30.420135\n",
      "Train Epoch: 43 [20480/60000 (34%)]\tLoss: -30.449373\n",
      "Train Epoch: 43 [21760/60000 (36%)]\tLoss: -30.450317\n",
      "Train Epoch: 43 [23040/60000 (38%)]\tLoss: -30.407635\n",
      "Train Epoch: 43 [24320/60000 (41%)]\tLoss: -30.342964\n",
      "Train Epoch: 43 [25600/60000 (43%)]\tLoss: -30.759710\n",
      "Train Epoch: 43 [26880/60000 (45%)]\tLoss: -30.745632\n",
      "Train Epoch: 43 [28160/60000 (47%)]\tLoss: -30.045429\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 209\u001b[0m\n\u001b[0;32m    207\u001b[0m test_loss_vals_total \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([])\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 209\u001b[0m     train_loss_vals \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m     test_loss_vals \u001b[38;5;241m=\u001b[39m test(epoch)\n\u001b[0;32m    211\u001b[0m     train_loss_vals_total \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(train_loss_vals_total, train_loss_vals)\n",
      "Cell \u001b[1;32mIn[1], line 149\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m    147\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    148\u001b[0m alphas, betas, mu, logvar \u001b[38;5;241m=\u001b[39m model(data)\n\u001b[1;32m--> 149\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mbeta_loss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43malphas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbetas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    151\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "Cell \u001b[1;32mIn[1], line 112\u001b[0m, in \u001b[0;36mbeta_loss_function\u001b[1;34m(alphas, betas, x, mu, logvar, beta_reg)\u001b[0m\n\u001b[0;32m    109\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m784\u001b[39m) \n\u001b[0;32m    111\u001b[0m clipped_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclamp(x, \u001b[38;5;241m1e-4\u001b[39m, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1e-4\u001b[39m)\n\u001b[1;32m--> 112\u001b[0m log_norm_const \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlgamma(alphas \u001b[38;5;241m+\u001b[39m betas) \u001b[38;5;241m-\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlgamma\u001b[49m\u001b[43m(\u001b[49m\u001b[43malphas\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mlgamma(betas)\n\u001b[0;32m    113\u001b[0m log_p_all \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum((alphas \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(clipped_x) \u001b[38;5;241m+\u001b[39m \\\n\u001b[0;32m    114\u001b[0m     (betas \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m clipped_x) \u001b[38;5;241m+\u001b[39m log_norm_const, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    115\u001b[0m log_p \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(log_p_all)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np \n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.pyplot as plt \n",
    "from torch.distributions import Beta\n",
    "\n",
    "\n",
    "DIM = 20\n",
    "EPOCHS = 100\n",
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=True, download=True,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=128, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('data', train=False,\n",
    "                   transform=transforms.ToTensor()),\n",
    "    batch_size=128, shuffle=False)\n",
    "\n",
    "# TA model in sheet3_solution.ipynb\n",
    "# altered according to https://github.com/cunningham-lab/cb_and_cc/blob/master/cb/utils.py\n",
    "class BetaDistVAE(nn.Module):\n",
    "    def __init__(self, hidden_dims=[500, 500, DIM, 500, 500], data_dim=784):\n",
    "        super().__init__()\n",
    "        assert len(hidden_dims) == 5, \"Insufficiently number of dimensions!\"\n",
    "        self.data_dim = data_dim\n",
    "        self.device = device\n",
    "        \n",
    "        # self.beta_reg = nn.Parameter(torch.ones(1))\n",
    "        # define IO\n",
    "        self.in_layer = nn.Linear(data_dim, hidden_dims[0])\n",
    "        self.out_layer = nn.Linear(hidden_dims[-1], 2*data_dim)\n",
    "        # self.out_layer_alpha = nn.Linear(hidden_dims[-1], data_dim)\n",
    "        # self.out_layer_beta = nn.Linear(hidden_dims[-1], data_dim)\n",
    "        # hidden layer\n",
    "        self.enc_h = nn.Linear(hidden_dims[0], hidden_dims[1])\n",
    "        # define hidden and latent\n",
    "        self.enc_mu = nn.Linear(hidden_dims[1], hidden_dims[2])\n",
    "        self.enc_sigma = nn.Linear(hidden_dims[1], hidden_dims[2])\n",
    "        # hidden layer decoder\n",
    "        self.dec_h = nn.Linear(hidden_dims[2], hidden_dims[-2])\n",
    "        self.dec_layer = nn.Linear(hidden_dims[-2], hidden_dims[-1])\n",
    "        self.to(device)\n",
    "        \n",
    "    def encode(self, x: torch.Tensor):\n",
    "        h1 = F.dropout(F.relu(self.in_layer(x)), p=0.1)\n",
    "        h2 = F.dropout(F.relu(self.enc_h(h1)), p=0.1)\n",
    "        return self.enc_mu(h2), self.enc_sigma(h2)\n",
    "\n",
    "    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        h3 = F.dropout(F.relu(self.dec_h(z)), p=0.1)\n",
    "        h4 = F.dropout(F.relu(self.dec_layer(h3)), p=0.1)\n",
    "        beta_params = self.out_layer(h4)\n",
    "        alphas = 1e-6 + F.softmax(beta_params[:, :self.data_dim])\n",
    "        betas = 1e-6 + F.softmax(beta_params[:, self.data_dim:])\n",
    "        # alphas = 1e-6 + F.relu(beta_params[:, :self.data_dim])\n",
    "        # betas = 1e-6 + F.relu(beta_params[:, self.data_dim:])\n",
    "        return alphas, betas\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        mu, logvar = self.encode(x.view(-1, self.data_dim))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        alphas, betas = self.decode(z)\n",
    "        return alphas, betas, mu, logvar\n",
    "\n",
    "\n",
    "model = BetaDistVAE().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n",
    "# https://github.com/Robert-Aduviri/Continuous-Bernoulli-VAE\n",
    "# the following function is copied from the above github repo \n",
    "# where I did not alter anything\n",
    "def sumlogC(x , eps = 1e-5):\n",
    "    '''\n",
    "    Numerically stable implementation of \n",
    "    sum of logarithm of Continous Bernoulli\n",
    "    constant C, using Taylor 2nd degree approximation\n",
    "        \n",
    "    Parameter\n",
    "    ----------\n",
    "    x : Tensor of dimensions (batch_size, dim)\n",
    "        x takes values in (0,1)\n",
    "    ''' \n",
    "    x = torch.clamp(x, eps, 1.-eps) \n",
    "    mask = torch.abs(x - 0.5).ge(eps)\n",
    "    far = torch.masked_select(x, mask)\n",
    "    close = torch.masked_select(x, ~mask)\n",
    "    far_values =  torch.log( (torch.log(1. - far) - torch.log(far)).div(1. - 2. * far) )\n",
    "    close_values = torch.log(torch.tensor((2.))) + torch.log(1. + torch.pow( 1. - 2. * close, 2)/3. )\n",
    "    return far_values.sum() + close_values.sum()\n",
    "\n",
    "# https://github.com/cunningham-lab/cb_and_cc/blob/master/cb/beta_distr_vae_mnist.ipynb \n",
    "# the following function is altered according to the above link\n",
    "def beta_loss_function(alphas, betas, x, mu, logvar, beta_reg):\n",
    "    x = x.view(-1, 784) \n",
    "        \n",
    "    clipped_x = torch.clamp(x, 1e-4, 1 - 1e-4)\n",
    "    log_norm_const = torch.lgamma(alphas + betas) - torch.lgamma(alphas) - torch.lgamma(betas)\n",
    "    log_p_all = torch.sum((alphas - 1.0) * torch.log(clipped_x) + \\\n",
    "        (betas - 1.0) * torch.log(1.0 - clipped_x) + log_norm_const, 1)\n",
    "    log_p = torch.mean(log_p_all)\n",
    "    std = torch.exp(0.5*logvar)\n",
    "    \n",
    "    # log_new = torch.mean(torch.digamma(alphas) - torch.digamma(alphas + betas))\n",
    "    \n",
    "    # log_iw = log_p_all + torch.sum(-0.5 * torch.square(z), 1)\n",
    "    # log_iw = log_iw + torch.sum(torch.log(1e-8 + std) + torch.square(mu - z) / (2.0 * torch.square(std)), 1)\n",
    "    KL = 0.5 * torch.sum(torch.square(mu) + torch.square(std) - torch.log(1e-8 + torch.square(std)) - 1.0, 1)\n",
    "    KL = torch.mean(KL)\n",
    "    \n",
    "    return -log_p + beta_reg * KL\n",
    "\n",
    "    # recon_dist = Beta(alphas, betas)\n",
    "    # recon_x = recon_dist.mean\n",
    "    # recon_x = recon_x.view(-1, 784)\n",
    "    # BCE = F.binary_cross_entropy(recon_x, x, reduction='sum') \n",
    "    # # see Appendix B from VAE paper:\n",
    "    # # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # # https://arxiv.org/abs/1312.6114\n",
    "    # # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    # KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    # # print(KLD.item()/KL.item())\n",
    "    # # logC = sumlogC(recon_x)\n",
    "    # return BCE + KLD #+ logC\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    train_loss_vals = []\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        alphas, betas, mu, logvar = model(data)\n",
    "        loss = beta_loss_function(alphas, betas, data, mu, logvar, 1)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        train_loss_vals.append(loss.item())\n",
    "        \n",
    "        optimizer.step()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.item() / len(data)))\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss))\n",
    "    \n",
    "    return np.array(train_loss_vals) / len(train_loader.dataset) * len(train_loader)\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_loss_vals = []\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            alphas, betas, mu, logvar = model(data)\n",
    "            loss = beta_loss_function(alphas, betas, data, mu, logvar, 1)\n",
    "            test_loss += loss.item()\n",
    "            test_loss_vals.append(loss.item())\n",
    "            \n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                recon_dist = Beta(alphas, betas)\n",
    "                # recon_batch = recon_dist.sample()\n",
    "                recon_batch = recon_dist.mean\n",
    "                recon_batch = recon_batch.view(128, 1, 28, 28)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                        recon_batch[:n]])\n",
    "                \n",
    "                save_image(comparison.cpu(),\n",
    "                           'betaresults/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "                # plt.figure(figsize=(10, 4))\n",
    "                # for i in range(1, 2*n+1):\n",
    "                #     ax = plt.subplot(2,n,i)\n",
    "                #     plt.imshow(comparison.cpu().detach().numpy()[i-1, 0,:,:], cmap=\"gray\")\n",
    "                #     ax.get_xaxis().set_visible(False)\n",
    "                #     ax.get_yaxis().set_visible(False)\n",
    "                #     ax.margins(0,0)\n",
    "                # plt.savefig('betaresults/reconstruction_' + str(epoch) + '.png')\n",
    "                # plt.close()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "\n",
    "    return np.array(test_loss_vals) / len(test_loader.dataset) * len(test_loader)\n",
    "\n",
    "train_loss_vals_total = np.array([])\n",
    "test_loss_vals_total = np.array([])\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_loss_vals = train(epoch)\n",
    "    test_loss_vals = test(epoch)\n",
    "    train_loss_vals_total = np.append(train_loss_vals_total, train_loss_vals)\n",
    "    test_loss_vals_total = np.append(test_loss_vals_total, test_loss_vals)\n",
    "    with torch.no_grad():\n",
    "        sample = torch.randn(64, DIM).to(device)\n",
    "        sample = model.decode(sample)\n",
    "        sample_dist = Beta(sample[0], sample[1])\n",
    "        # sample = sample_dist.sample()\n",
    "        sample = sample_dist.mean\n",
    "        save_image(sample.view(64, 1, 28, 28),\n",
    "                    'betaresults/sample_' + str(epoch) + '.png')\n",
    "\n",
    "torch.save(model, 'trained_models/betavae.pt')\n",
    "np.save('tmp/betavae_train_loss_vals_total.npy', train_loss_vals_total)\n",
    "np.save('tmp/betavae_test_loss_vals_total.npy', test_loss_vals_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'BetaVAE ELBO loss over batches')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_loss_vals_total, label=\"train\")\n",
    "plt.plot([i*6 for i in range(len(test_loss_vals_total))], test_loss_vals_total, label=\"test\")\n",
    "plt.legend()\n",
    "plt.title(\"BetaVAE ELBO loss over batches\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyro-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
